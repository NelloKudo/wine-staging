From cbcb5b1b3d5d5d01495c71b121d8380581b539d5 Mon Sep 17 00:00:00 2001
From: Alistair Leslie-Hughes <leslie_alistair@hotmail.com>
Date: Sat, 11 Jan 2025 11:27:47 +1100
Subject: [PATCH] Updated vkd3d to 4227858cfee7d4c1a0bf0ff9f59e45fca619e79d.

---
 libs/vkd3d/libs/vkd3d-shader/fx.c             |  12 +-
 libs/vkd3d/libs/vkd3d-shader/hlsl.c           | 108 +--
 libs/vkd3d/libs/vkd3d-shader/hlsl.h           |  18 +-
 libs/vkd3d/libs/vkd3d-shader/hlsl.y           | 181 +++--
 libs/vkd3d/libs/vkd3d-shader/hlsl_codegen.c   | 767 +++++++++++++++---
 .../libs/vkd3d-shader/hlsl_constant_ops.c     | 222 +++--
 libs/vkd3d/libs/vkd3d-shader/ir.c             |   9 +-
 libs/vkd3d/libs/vkd3d-shader/spirv.c          |   5 +-
 libs/vkd3d/libs/vkd3d-shader/tpf.c            | 504 ------------
 .../libs/vkd3d-shader/vkd3d_shader_main.c     |   6 +-
 libs/vkd3d/libs/vkd3d/state.c                 |   5 +-
 11 files changed, 962 insertions(+), 875 deletions(-)

diff --git a/libs/vkd3d/libs/vkd3d-shader/fx.c b/libs/vkd3d/libs/vkd3d-shader/fx.c
index 3795add87c7..779ffa1e156 100644
--- a/libs/vkd3d/libs/vkd3d-shader/fx.c
+++ b/libs/vkd3d/libs/vkd3d-shader/fx.c
@@ -610,8 +610,8 @@ static uint32_t get_fx_4_numeric_type_description(const struct hlsl_type *type,
             return 0;
     }
 
-    value |= (type->dimy & 0x7) << FX_4_NUMERIC_ROWS_SHIFT;
-    value |= (type->dimx & 0x7) << FX_4_NUMERIC_COLUMNS_SHIFT;
+    value |= (type->e.numeric.dimy & 0x7) << FX_4_NUMERIC_ROWS_SHIFT;
+    value |= (type->e.numeric.dimx & 0x7) << FX_4_NUMERIC_COLUMNS_SHIFT;
     if (type->modifiers & HLSL_MODIFIER_COLUMN_MAJOR)
         value |= FX_4_NUMERIC_COLUMN_MAJOR_MASK;
 
@@ -1047,13 +1047,13 @@ static uint32_t write_fx_2_parameter(const struct hlsl_type *type, const char *n
     switch (type->class)
     {
         case HLSL_CLASS_VECTOR:
-            put_u32(buffer, type->dimx);
-            put_u32(buffer, type->dimy);
+            put_u32(buffer, type->e.numeric.dimx);
+            put_u32(buffer, type->e.numeric.dimy);
             break;
         case HLSL_CLASS_SCALAR:
         case HLSL_CLASS_MATRIX:
-            put_u32(buffer, type->dimy);
-            put_u32(buffer, type->dimx);
+            put_u32(buffer, type->e.numeric.dimy);
+            put_u32(buffer, type->e.numeric.dimx);
             break;
         case HLSL_CLASS_STRUCT:
             put_u32(buffer, type->e.record.field_count);
diff --git a/libs/vkd3d/libs/vkd3d-shader/hlsl.c b/libs/vkd3d/libs/vkd3d-shader/hlsl.c
index 84da2fcbc9f..858186a1071 100644
--- a/libs/vkd3d/libs/vkd3d-shader/hlsl.c
+++ b/libs/vkd3d/libs/vkd3d-shader/hlsl.c
@@ -192,18 +192,20 @@ bool hlsl_type_is_row_major(const struct hlsl_type *type)
 
 unsigned int hlsl_type_minor_size(const struct hlsl_type *type)
 {
+    VKD3D_ASSERT(hlsl_is_numeric_type(type));
     if (type->class != HLSL_CLASS_MATRIX || hlsl_type_is_row_major(type))
-        return type->dimx;
+        return type->e.numeric.dimx;
     else
-        return type->dimy;
+        return type->e.numeric.dimy;
 }
 
 unsigned int hlsl_type_major_size(const struct hlsl_type *type)
 {
+    VKD3D_ASSERT(hlsl_is_numeric_type(type));
     if (type->class != HLSL_CLASS_MATRIX || hlsl_type_is_row_major(type))
-        return type->dimy;
+        return type->e.numeric.dimy;
     else
-        return type->dimx;
+        return type->e.numeric.dimx;
 }
 
 unsigned int hlsl_type_element_count(const struct hlsl_type *type)
@@ -211,7 +213,7 @@ unsigned int hlsl_type_element_count(const struct hlsl_type *type)
     switch (type->class)
     {
         case HLSL_CLASS_VECTOR:
-            return type->dimx;
+            return type->e.numeric.dimx;
         case HLSL_CLASS_MATRIX:
             return hlsl_type_major_size(type);
         case HLSL_CLASS_ARRAY:
@@ -355,14 +357,24 @@ static void hlsl_type_calculate_reg_size(struct hlsl_ctx *ctx, struct hlsl_type
     {
         case HLSL_CLASS_SCALAR:
         case HLSL_CLASS_VECTOR:
-            type->reg_size[HLSL_REGSET_NUMERIC] = is_sm4 ? type->dimx : 4;
+            type->reg_size[HLSL_REGSET_NUMERIC] = is_sm4 ? type->e.numeric.dimx : 4;
             break;
 
         case HLSL_CLASS_MATRIX:
             if (hlsl_type_is_row_major(type))
-                type->reg_size[HLSL_REGSET_NUMERIC] = is_sm4 ? (4 * (type->dimy - 1) + type->dimx) : (4 * type->dimy);
+            {
+                if (is_sm4)
+                    type->reg_size[HLSL_REGSET_NUMERIC] = 4 * (type->e.numeric.dimy - 1) + type->e.numeric.dimx;
+                else
+                    type->reg_size[HLSL_REGSET_NUMERIC] = 4 * type->e.numeric.dimy;
+            }
             else
-                type->reg_size[HLSL_REGSET_NUMERIC] = is_sm4 ? (4 * (type->dimx - 1) + type->dimy) : (4 * type->dimx);
+            {
+                if (is_sm4)
+                    type->reg_size[HLSL_REGSET_NUMERIC] = 4 * (type->e.numeric.dimx - 1) + type->e.numeric.dimy;
+                else
+                    type->reg_size[HLSL_REGSET_NUMERIC] = 4 * type->e.numeric.dimx;
+            }
             break;
 
         case HLSL_CLASS_ARRAY:
@@ -387,7 +399,6 @@ static void hlsl_type_calculate_reg_size(struct hlsl_ctx *ctx, struct hlsl_type
         {
             unsigned int i;
 
-            type->dimx = 0;
             for (i = 0; i < type->e.record.field_count; ++i)
             {
                 struct hlsl_struct_field *field = &type->e.record.fields[i];
@@ -399,8 +410,6 @@ static void hlsl_type_calculate_reg_size(struct hlsl_ctx *ctx, struct hlsl_type
                     field->reg_offset[k] = type->reg_size[k];
                     type->reg_size[k] += field->type->reg_size[k];
                 }
-
-                type->dimx += field->type->dimx * field->type->dimy * hlsl_get_multiarray_size(field->type);
             }
             break;
         }
@@ -483,8 +492,8 @@ static struct hlsl_type *hlsl_new_type(struct hlsl_ctx *ctx, const char *name, e
     }
     type->class = type_class;
     type->e.numeric.type = base_type;
-    type->dimx = dimx;
-    type->dimy = dimy;
+    type->e.numeric.dimx = dimx;
+    type->e.numeric.dimy = dimy;
     hlsl_type_calculate_reg_size(ctx, type);
 
     list_add_tail(&ctx->types, &type->entry);
@@ -552,18 +561,19 @@ static unsigned int traverse_path_from_component_index(struct hlsl_ctx *ctx,
     switch (type->class)
     {
         case HLSL_CLASS_VECTOR:
-            VKD3D_ASSERT(index < type->dimx);
+            VKD3D_ASSERT(index < type->e.numeric.dimx);
             *type_ptr = hlsl_get_scalar_type(ctx, type->e.numeric.type);
             *index_ptr = 0;
             return index;
 
         case HLSL_CLASS_MATRIX:
         {
-            unsigned int y = index / type->dimx, x = index % type->dimx;
+            unsigned int y = index / type->e.numeric.dimx, x = index % type->e.numeric.dimx;
             bool row_major = hlsl_type_is_row_major(type);
 
-            VKD3D_ASSERT(index < type->dimx * type->dimy);
-            *type_ptr = hlsl_get_vector_type(ctx, type->e.numeric.type, row_major ? type->dimx : type->dimy);
+            VKD3D_ASSERT(index < type->e.numeric.dimx * type->e.numeric.dimy);
+            *type_ptr = hlsl_get_vector_type(ctx, type->e.numeric.type,
+                    row_major ? type->e.numeric.dimx : type->e.numeric.dimy);
             *index_ptr = row_major ? x : y;
             return row_major ? y : x;
         }
@@ -861,9 +871,9 @@ struct hlsl_type *hlsl_get_element_type_from_path_index(struct hlsl_ctx *ctx, co
 
         case HLSL_CLASS_MATRIX:
             if (hlsl_type_is_row_major(type))
-                return hlsl_get_vector_type(ctx, type->e.numeric.type, type->dimx);
+                return hlsl_get_vector_type(ctx, type->e.numeric.type, type->e.numeric.dimx);
             else
-                return hlsl_get_vector_type(ctx, type->e.numeric.type, type->dimy);
+                return hlsl_get_vector_type(ctx, type->e.numeric.type, type->e.numeric.dimy);
 
         case HLSL_CLASS_ARRAY:
             return type->e.array.type;
@@ -892,8 +902,6 @@ struct hlsl_type *hlsl_new_array_type(struct hlsl_ctx *ctx, struct hlsl_type *ba
     type->modifiers = basic_type->modifiers;
     type->e.array.elements_count = array_size;
     type->e.array.type = basic_type;
-    type->dimx = basic_type->dimx;
-    type->dimy = basic_type->dimy;
     type->sampler_dim = basic_type->sampler_dim;
     hlsl_type_calculate_reg_size(ctx, type);
 
@@ -927,7 +935,6 @@ struct hlsl_type *hlsl_new_struct_type(struct hlsl_ctx *ctx, const char *name,
         return NULL;
     type->class = HLSL_CLASS_STRUCT;
     type->name = name;
-    type->dimy = 1;
     type->e.record.fields = fields;
     type->e.record.field_count = field_count;
     hlsl_type_calculate_reg_size(ctx, type);
@@ -945,8 +952,6 @@ struct hlsl_type *hlsl_new_texture_type(struct hlsl_ctx *ctx, enum hlsl_sampler_
     if (!(type = hlsl_alloc(ctx, sizeof(*type))))
         return NULL;
     type->class = HLSL_CLASS_TEXTURE;
-    type->dimx = 4;
-    type->dimy = 1;
     type->sampler_dim = dim;
     type->e.resource.format = format;
     type->sample_count = sample_count;
@@ -963,8 +968,6 @@ struct hlsl_type *hlsl_new_uav_type(struct hlsl_ctx *ctx, enum hlsl_sampler_dim
     if (!(type = hlsl_alloc(ctx, sizeof(*type))))
         return NULL;
     type->class = HLSL_CLASS_UAV;
-    type->dimx = format->dimx;
-    type->dimy = 1;
     type->sampler_dim = dim;
     type->e.resource.format = format;
     type->e.resource.rasteriser_ordered = rasteriser_ordered;
@@ -980,7 +983,6 @@ struct hlsl_type *hlsl_new_cb_type(struct hlsl_ctx *ctx, struct hlsl_type *forma
     if (!(type = hlsl_alloc(ctx, sizeof(*type))))
         return NULL;
     type->class = HLSL_CLASS_CONSTANT_BUFFER;
-    type->dimy = 1;
     type->e.resource.format = format;
     hlsl_type_calculate_reg_size(ctx, type);
     list_add_tail(&ctx->types, &type->entry);
@@ -1066,7 +1068,7 @@ unsigned int hlsl_type_component_count(const struct hlsl_type *type)
         case HLSL_CLASS_SCALAR:
         case HLSL_CLASS_VECTOR:
         case HLSL_CLASS_MATRIX:
-            return type->dimx * type->dimy;
+            return type->e.numeric.dimx * type->e.numeric.dimy;
 
         case HLSL_CLASS_STRUCT:
         {
@@ -1131,9 +1133,9 @@ bool hlsl_types_are_equal(const struct hlsl_type *t1, const struct hlsl_type *t2
             if ((t1->modifiers & HLSL_MODIFIER_ROW_MAJOR)
                     != (t2->modifiers & HLSL_MODIFIER_ROW_MAJOR))
                 return false;
-            if (t1->dimx != t2->dimx)
+            if (t1->e.numeric.dimx != t2->e.numeric.dimx)
                 return false;
-            if (t1->dimy != t2->dimy)
+            if (t1->e.numeric.dimy != t2->e.numeric.dimy)
                 return false;
             return true;
 
@@ -1224,8 +1226,6 @@ struct hlsl_type *hlsl_type_clone(struct hlsl_ctx *ctx, struct hlsl_type *old,
         }
     }
     type->class = old->class;
-    type->dimx = old->dimx;
-    type->dimy = old->dimy;
     type->modifiers = old->modifiers | modifiers;
     if (!(type->modifiers & HLSL_MODIFIERS_MAJORITY_MASK))
         type->modifiers |= default_majority;
@@ -1238,6 +1238,8 @@ struct hlsl_type *hlsl_type_clone(struct hlsl_ctx *ctx, struct hlsl_type *old,
         case HLSL_CLASS_SCALAR:
         case HLSL_CLASS_VECTOR:
         case HLSL_CLASS_MATRIX:
+            type->e.numeric.dimx = old->e.numeric.dimx;
+            type->e.numeric.dimy = old->e.numeric.dimy;
             type->e.numeric.type = old->e.numeric.type;
             break;
 
@@ -1497,7 +1499,7 @@ struct hlsl_ir_node *hlsl_new_store_index(struct hlsl_ctx *ctx, const struct hls
     hlsl_src_from_node(&store->rhs, rhs);
 
     if (!writemask && type_is_single_reg(rhs->data_type))
-        writemask = (1 << rhs->data_type->dimx) - 1;
+        writemask = (1 << rhs->data_type->e.numeric.dimx) - 1;
     store->writemask = writemask;
 
     return &store->node;
@@ -1524,7 +1526,7 @@ bool hlsl_new_store_component(struct hlsl_ctx *ctx, struct hlsl_block *block,
     hlsl_src_from_node(&store->rhs, rhs);
 
     if (type_is_single_reg(rhs->data_type))
-        store->writemask = (1 << rhs->data_type->dimx) - 1;
+        store->writemask = (1 << rhs->data_type->e.numeric.dimx) - 1;
 
     hlsl_block_add_instr(block, &store->node);
 
@@ -2064,7 +2066,7 @@ struct hlsl_ir_node *hlsl_new_index(struct hlsl_ctx *ctx, struct hlsl_ir_node *v
     if (type->class == HLSL_CLASS_TEXTURE || type->class == HLSL_CLASS_UAV)
         type = type->e.resource.format;
     else if (type->class == HLSL_CLASS_MATRIX)
-        type = hlsl_get_vector_type(ctx, type->e.numeric.type, type->dimx);
+        type = hlsl_get_vector_type(ctx, type->e.numeric.type, type->e.numeric.dimx);
     else
         type = hlsl_get_element_type_from_path_index(ctx, type, idx);
 
@@ -2355,10 +2357,10 @@ static struct hlsl_ir_node *clone_swizzle(struct hlsl_ctx *ctx,
         struct clone_instr_map *map, struct hlsl_ir_swizzle *src)
 {
     if (src->val.node->data_type->class == HLSL_CLASS_MATRIX)
-        return hlsl_new_matrix_swizzle(ctx, src->u.matrix, src->node.data_type->dimx,
+        return hlsl_new_matrix_swizzle(ctx, src->u.matrix, src->node.data_type->e.numeric.dimx,
                 map_instr(map, src->val.node), &src->node.loc);
     else
-        return hlsl_new_swizzle(ctx, src->u.vector, src->node.data_type->dimx,
+        return hlsl_new_swizzle(ctx, src->u.vector, src->node.data_type->e.numeric.dimx,
                 map_instr(map, src->val.node), &src->node.loc);
 }
 
@@ -2778,12 +2780,13 @@ static void hlsl_dump_type(struct vkd3d_string_buffer *buffer, const struct hlsl
 
         case HLSL_CLASS_VECTOR:
             VKD3D_ASSERT(type->e.numeric.type < ARRAY_SIZE(base_types));
-            vkd3d_string_buffer_printf(buffer, "%s%u", base_types[type->e.numeric.type], type->dimx);
+            vkd3d_string_buffer_printf(buffer, "%s%u", base_types[type->e.numeric.type], type->e.numeric.dimx);
             return;
 
         case HLSL_CLASS_MATRIX:
             VKD3D_ASSERT(type->e.numeric.type < ARRAY_SIZE(base_types));
-            vkd3d_string_buffer_printf(buffer, "%s%ux%u", base_types[type->e.numeric.type], type->dimy, type->dimx);
+            vkd3d_string_buffer_printf(buffer, "%s%ux%u", base_types[type->e.numeric.type],
+                    type->e.numeric.dimy, type->e.numeric.dimx);
             return;
 
         case HLSL_CLASS_ARRAY:
@@ -3176,9 +3179,9 @@ static void dump_ir_constant(struct vkd3d_string_buffer *buffer, const struct hl
     struct hlsl_type *type = constant->node.data_type;
     unsigned int x;
 
-    if (type->dimx != 1)
+    if (type->e.numeric.dimx != 1)
         vkd3d_string_buffer_printf(buffer, "{");
-    for (x = 0; x < type->dimx; ++x)
+    for (x = 0; x < type->e.numeric.dimx; ++x)
     {
         const union hlsl_constant_value_component *value = &constant->value.u[x];
 
@@ -3204,12 +3207,9 @@ static void dump_ir_constant(struct vkd3d_string_buffer *buffer, const struct hl
             case HLSL_TYPE_UINT:
                 vkd3d_string_buffer_printf(buffer, "%u ", value->u);
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
     }
-    if (type->dimx != 1)
+    if (type->e.numeric.dimx != 1)
         vkd3d_string_buffer_printf(buffer, "}");
 }
 
@@ -3435,16 +3435,17 @@ static void dump_ir_swizzle(struct vkd3d_string_buffer *buffer, const struct hls
     unsigned int i;
 
     dump_src(buffer, &swizzle->val);
-    if (swizzle->val.node->data_type->dimy > 1)
+    if (swizzle->val.node->data_type->e.numeric.dimy > 1)
     {
         vkd3d_string_buffer_printf(buffer, ".");
-        for (i = 0; i < swizzle->node.data_type->dimx; ++i)
+        for (i = 0; i < swizzle->node.data_type->e.numeric.dimx; ++i)
             vkd3d_string_buffer_printf(buffer, "_m%u%u",
                     swizzle->u.matrix.components[i].y, swizzle->u.matrix.components[i].x);
     }
     else
     {
-        vkd3d_string_buffer_printf(buffer, "%s", debug_hlsl_swizzle(swizzle->u.vector, swizzle->node.data_type->dimx));
+        vkd3d_string_buffer_printf(buffer, "%s",
+                debug_hlsl_swizzle(swizzle->u.vector, swizzle->node.data_type->e.numeric.dimx));
     }
 }
 
@@ -3658,10 +3659,15 @@ void hlsl_dump_var_default_values(const struct hlsl_ir_var *var)
 
 void hlsl_replace_node(struct hlsl_ir_node *old, struct hlsl_ir_node *new)
 {
+    const struct hlsl_type *old_type = old->data_type, *new_type = new->data_type;
     struct hlsl_src *src, *next;
 
-    VKD3D_ASSERT(old->data_type == new->data_type || old->data_type->dimx == new->data_type->dimx);
-    VKD3D_ASSERT(old->data_type == new->data_type || old->data_type->dimy == new->data_type->dimy);
+    if (hlsl_is_numeric_type(old_type))
+    {
+        VKD3D_ASSERT(hlsl_is_numeric_type(new_type));
+        VKD3D_ASSERT(old_type->e.numeric.dimx == new_type->e.numeric.dimx);
+        VKD3D_ASSERT(old_type->e.numeric.dimy == new_type->e.numeric.dimy);
+    }
 
     LIST_FOR_EACH_ENTRY_SAFE(src, next, &old->uses, struct hlsl_src, entry)
     {
@@ -4331,7 +4337,7 @@ static void declare_predefined_types(struct hlsl_ctx *ctx)
     }
 
     ctx->builtin_types.Void = hlsl_new_simple_type(ctx, "void", HLSL_CLASS_VOID);
-    ctx->builtin_types.null = hlsl_new_type(ctx, "NULL", HLSL_CLASS_NULL, HLSL_TYPE_UINT, 1, 1);
+    ctx->builtin_types.null = hlsl_new_simple_type(ctx, "NULL", HLSL_CLASS_NULL);
     ctx->builtin_types.string = hlsl_new_simple_type(ctx, "string", HLSL_CLASS_STRING);
     ctx->builtin_types.error = hlsl_new_simple_type(ctx, "<error type>", HLSL_CLASS_ERROR);
     hlsl_scope_add_type(ctx->globals, ctx->builtin_types.string);
diff --git a/libs/vkd3d/libs/vkd3d-shader/hlsl.h b/libs/vkd3d/libs/vkd3d-shader/hlsl.h
index b0e2b54c348..d712a325322 100644
--- a/libs/vkd3d/libs/vkd3d-shader/hlsl.h
+++ b/libs/vkd3d/libs/vkd3d-shader/hlsl.h
@@ -169,16 +169,6 @@ struct hlsl_type
      * Modifiers that don't fall inside this mask are to be stored in the variable in
      *   hlsl_ir_var.modifiers, or in the struct field in hlsl_ir_field.modifiers. */
     uint32_t modifiers;
-    /* Size of the type values on each dimension. For non-numeric types, they are set for the
-     *   convenience of the sm1/sm4 backends.
-     * If type is HLSL_CLASS_SCALAR, then both dimx = 1 and dimy = 1.
-     * If type is HLSL_CLASS_VECTOR, then dimx is the size of the vector, and dimy = 1.
-     * If type is HLSL_CLASS_MATRIX, then dimx is the number of columns, and dimy the number of rows.
-     * If type is HLSL_CLASS_ARRAY, then dimx and dimy have the same value as in the type of the array elements.
-     * If type is HLSL_CLASS_STRUCT, then dimx is the sum of (dimx * dimy) of every component, and dimy = 1.
-     */
-    unsigned int dimx;
-    unsigned int dimy;
     /* Sample count for HLSL_SAMPLER_DIM_2DMS or HLSL_SAMPLER_DIM_2DMSARRAY. */
     unsigned int sample_count;
 
@@ -188,6 +178,10 @@ struct hlsl_type
         struct
         {
             enum hlsl_base_type type;
+            /* For scalars, dimx == dimy == 1.
+             * For vectors, dimx == vector width; dimy == 1.
+             * For matrices, dimx == column count; dimy == row count. */
+            unsigned int dimx, dimy;
         } numeric;
         /* Additional information if type is HLSL_CLASS_STRUCT. */
         struct
@@ -1684,10 +1678,6 @@ struct extern_resource
     struct vkd3d_shader_location loc;
 };
 
-struct extern_resource *sm4_get_extern_resources(struct hlsl_ctx *ctx, unsigned int *count);
-void sm4_free_extern_resources(struct extern_resource *extern_resources, unsigned int count);
-void sm4_generate_rdef(struct hlsl_ctx *ctx, struct vkd3d_shader_code *rdef);
-
 struct hlsl_ir_function_decl *hlsl_compile_internal_function(struct hlsl_ctx *ctx, const char *name, const char *hlsl);
 
 int hlsl_lexer_compile(struct hlsl_ctx *ctx, const struct vkd3d_shader_code *hlsl);
diff --git a/libs/vkd3d/libs/vkd3d-shader/hlsl.y b/libs/vkd3d/libs/vkd3d-shader/hlsl.y
index dbed11cd8b3..e6eaac78994 100644
--- a/libs/vkd3d/libs/vkd3d-shader/hlsl.y
+++ b/libs/vkd3d/libs/vkd3d-shader/hlsl.y
@@ -247,18 +247,19 @@ static bool type_contains_only_numerics(const struct hlsl_type *type)
 
 static bool explicit_compatible_data_types(struct hlsl_ctx *ctx, struct hlsl_type *src, struct hlsl_type *dst)
 {
-    if (hlsl_is_numeric_type(src) && src->dimx == 1 && src->dimy == 1 && type_contains_only_numerics(dst))
+    if (hlsl_is_numeric_type(src) && src->e.numeric.dimx == 1 && src->e.numeric.dimy == 1
+            && type_contains_only_numerics(dst))
         return true;
 
     if (src->class == HLSL_CLASS_MATRIX && dst->class == HLSL_CLASS_MATRIX
-            && src->dimx >= dst->dimx && src->dimy >= dst->dimy)
+            && src->e.numeric.dimx >= dst->e.numeric.dimx && src->e.numeric.dimy >= dst->e.numeric.dimy)
         return true;
 
-    if ((src->class == HLSL_CLASS_MATRIX && src->dimx > 1 && src->dimy > 1)
+    if ((src->class == HLSL_CLASS_MATRIX && src->e.numeric.dimx > 1 && src->e.numeric.dimy > 1)
             && hlsl_type_component_count(src) != hlsl_type_component_count(dst))
         return false;
 
-    if ((dst->class == HLSL_CLASS_MATRIX && dst->dimy > 1)
+    if ((dst->class == HLSL_CLASS_MATRIX && dst->e.numeric.dimy > 1)
             && hlsl_type_component_count(src) != hlsl_type_component_count(dst))
         return false;
 
@@ -273,16 +274,16 @@ static bool implicit_compatible_data_types(struct hlsl_ctx *ctx, struct hlsl_typ
     if (hlsl_is_numeric_type(src))
     {
         /* Scalar vars can be converted to any other numeric data type */
-        if (src->dimx == 1 && src->dimy == 1)
+        if (src->e.numeric.dimx == 1 && src->e.numeric.dimy == 1)
             return true;
         /* The other way around is true too */
-        if (dst->dimx == 1 && dst->dimy == 1)
+        if (dst->e.numeric.dimx == 1 && dst->e.numeric.dimy == 1)
             return true;
 
         if (src->class == HLSL_CLASS_MATRIX || dst->class == HLSL_CLASS_MATRIX)
         {
             if (src->class == HLSL_CLASS_MATRIX && dst->class == HLSL_CLASS_MATRIX)
-                return src->dimx >= dst->dimx && src->dimy >= dst->dimy;
+                return src->e.numeric.dimx >= dst->e.numeric.dimx && src->e.numeric.dimy >= dst->e.numeric.dimy;
 
             /* Matrix-vector conversion is apparently allowed if they have
             * the same components count, or if the matrix is 1xN or Nx1
@@ -292,8 +293,8 @@ static bool implicit_compatible_data_types(struct hlsl_ctx *ctx, struct hlsl_typ
                 if (hlsl_type_component_count(src) == hlsl_type_component_count(dst))
                     return true;
 
-                if ((src->class == HLSL_CLASS_VECTOR || src->dimx == 1 || src->dimy == 1) &&
-                        (dst->class == HLSL_CLASS_VECTOR || dst->dimx == 1 || dst->dimy == 1))
+                if ((src->class == HLSL_CLASS_VECTOR || src->e.numeric.dimx == 1 || src->e.numeric.dimy == 1)
+                        && (dst->class == HLSL_CLASS_VECTOR || dst->e.numeric.dimx == 1 || dst->e.numeric.dimy == 1))
                     return hlsl_type_component_count(src) >= hlsl_type_component_count(dst);
             }
 
@@ -301,7 +302,7 @@ static bool implicit_compatible_data_types(struct hlsl_ctx *ctx, struct hlsl_typ
         }
         else
         {
-            return src->dimx >= dst->dimx;
+            return src->e.numeric.dimx >= dst->e.numeric.dimx;
         }
     }
 
@@ -335,7 +336,7 @@ static void check_condition_type(struct hlsl_ctx *ctx, const struct hlsl_ir_node
     if (type->class == HLSL_CLASS_ERROR)
         return;
 
-    if (type->class > HLSL_CLASS_LAST_NUMERIC || type->dimx > 1 || type->dimy > 1)
+    if (type->class > HLSL_CLASS_LAST_NUMERIC || type->e.numeric.dimx > 1 || type->e.numeric.dimy > 1)
     {
         struct vkd3d_string_buffer *string;
 
@@ -368,14 +369,14 @@ static struct hlsl_ir_node *add_cast(struct hlsl_ctx *ctx, struct hlsl_block *bl
         struct hlsl_ir_var *var;
         unsigned int dst_idx;
 
-        broadcast = hlsl_is_numeric_type(src_type) && src_type->dimx == 1 && src_type->dimy == 1;
+        broadcast = hlsl_is_numeric_type(src_type) && src_type->e.numeric.dimx == 1 && src_type->e.numeric.dimy == 1;
         matrix_cast = !broadcast && dst_comp_count != src_comp_count
                 && src_type->class == HLSL_CLASS_MATRIX && dst_type->class == HLSL_CLASS_MATRIX;
         VKD3D_ASSERT(src_comp_count >= dst_comp_count || broadcast);
         if (matrix_cast)
         {
-            VKD3D_ASSERT(dst_type->dimx <= src_type->dimx);
-            VKD3D_ASSERT(dst_type->dimy <= src_type->dimy);
+            VKD3D_ASSERT(dst_type->e.numeric.dimx <= src_type->e.numeric.dimx);
+            VKD3D_ASSERT(dst_type->e.numeric.dimy <= src_type->e.numeric.dimy);
         }
 
         if (!(var = hlsl_new_synthetic_var(ctx, "cast", dst_type, loc)))
@@ -395,9 +396,9 @@ static struct hlsl_ir_node *add_cast(struct hlsl_ctx *ctx, struct hlsl_block *bl
             }
             else if (matrix_cast)
             {
-                unsigned int x = dst_idx % dst_type->dimx, y = dst_idx / dst_type->dimx;
+                unsigned int x = dst_idx % dst_type->e.numeric.dimx, y = dst_idx / dst_type->e.numeric.dimx;
 
-                src_idx = y * src_type->dimx + x;
+                src_idx = y * src_type->e.numeric.dimx + x;
             }
             else
             {
@@ -458,7 +459,9 @@ static struct hlsl_ir_node *add_implicit_conversion(struct hlsl_ctx *ctx, struct
         return NULL;
     }
 
-    if (dst_type->dimx * dst_type->dimy < src_type->dimx * src_type->dimy && ctx->warn_implicit_truncation)
+    if (hlsl_is_numeric_type(dst_type) && hlsl_is_numeric_type(src_type)
+            && dst_type->e.numeric.dimx * dst_type->e.numeric.dimy < src_type->e.numeric.dimx * src_type->e.numeric.dimy
+            && ctx->warn_implicit_truncation)
         hlsl_warning(ctx, loc, VKD3D_SHADER_WARNING_HLSL_IMPLICIT_TRUNCATION, "Implicit truncation of %s type.",
                 src_type->class == HLSL_CLASS_VECTOR ? "vector" : "matrix");
 
@@ -874,7 +877,7 @@ static struct hlsl_ir_node *get_swizzle(struct hlsl_ctx *ctx, struct hlsl_ir_nod
                 x = swizzle[i + 2] - '1';
             }
 
-            if (x >= value->data_type->dimx || y >= value->data_type->dimy)
+            if (x >= value->data_type->e.numeric.dimx || y >= value->data_type->e.numeric.dimy)
                 return NULL;
             s.components[component].x = x;
             s.components[component].y = y;
@@ -907,7 +910,7 @@ static struct hlsl_ir_node *get_swizzle(struct hlsl_ctx *ctx, struct hlsl_ir_nod
                 break;
             }
 
-            if (s >= value->data_type->dimx)
+            if (s >= value->data_type->e.numeric.dimx)
                 return NULL;
             hlsl_swizzle_set_component(&swiz, component++, s);
         }
@@ -1021,7 +1024,7 @@ static bool add_array_access(struct hlsl_ctx *ctx, struct hlsl_block *block, str
     {
         unsigned int dim_count = hlsl_sampler_dim_count(expr_type->sampler_dim);
 
-        if (index_type->class > HLSL_CLASS_VECTOR || index_type->dimx != dim_count)
+        if (index_type->class > HLSL_CLASS_VECTOR || index_type->e.numeric.dimx != dim_count)
         {
             struct vkd3d_string_buffer *string;
 
@@ -1574,7 +1577,7 @@ static struct hlsl_block *make_block(struct hlsl_ctx *ctx, struct hlsl_ir_node *
 static bool expr_compatible_data_types(struct hlsl_type *t1, struct hlsl_type *t2)
 {
     /* Scalar vars can be converted to pretty much everything */
-    if ((t1->dimx == 1 && t1->dimy == 1) || (t2->dimx == 1 && t2->dimy == 1))
+    if ((t1->e.numeric.dimx == 1 && t1->e.numeric.dimy == 1) || (t2->e.numeric.dimx == 1 && t2->e.numeric.dimy == 1))
         return true;
 
     if (t1->class == HLSL_CLASS_VECTOR && t2->class == HLSL_CLASS_VECTOR)
@@ -1589,13 +1592,13 @@ static bool expr_compatible_data_types(struct hlsl_type *t1, struct hlsl_type *t
             if (hlsl_type_component_count(t1) == hlsl_type_component_count(t2))
                 return true;
 
-            return (t1->class == HLSL_CLASS_MATRIX && (t1->dimx == 1 || t1->dimy == 1))
-                    || (t2->class == HLSL_CLASS_MATRIX && (t2->dimx == 1 || t2->dimy == 1));
+            return (t1->class == HLSL_CLASS_MATRIX && (t1->e.numeric.dimx == 1 || t1->e.numeric.dimy == 1))
+                    || (t2->class == HLSL_CLASS_MATRIX && (t2->e.numeric.dimx == 1 || t2->e.numeric.dimy == 1));
         }
 
         /* Both matrices */
-        if ((t1->dimx >= t2->dimx && t1->dimy >= t2->dimy)
-                || (t1->dimx <= t2->dimx && t1->dimy <= t2->dimy))
+        if ((t1->e.numeric.dimx >= t2->e.numeric.dimx && t1->e.numeric.dimy >= t2->e.numeric.dimy)
+                || (t1->e.numeric.dimx <= t2->e.numeric.dimx && t1->e.numeric.dimy <= t2->e.numeric.dimy))
             return true;
     }
 
@@ -1655,37 +1658,37 @@ static bool expr_common_shape(struct hlsl_ctx *ctx, struct hlsl_type *t1, struct
         return false;
     }
 
-    if (t1->dimx == 1 && t1->dimy == 1)
+    if (t1->e.numeric.dimx == 1 && t1->e.numeric.dimy == 1)
     {
         *type = t2->class;
-        *dimx = t2->dimx;
-        *dimy = t2->dimy;
+        *dimx = t2->e.numeric.dimx;
+        *dimy = t2->e.numeric.dimy;
     }
-    else if (t2->dimx == 1 && t2->dimy == 1)
+    else if (t2->e.numeric.dimx == 1 && t2->e.numeric.dimy == 1)
     {
         *type = t1->class;
-        *dimx = t1->dimx;
-        *dimy = t1->dimy;
+        *dimx = t1->e.numeric.dimx;
+        *dimy = t1->e.numeric.dimy;
     }
     else if (t1->class == HLSL_CLASS_MATRIX && t2->class == HLSL_CLASS_MATRIX)
     {
         *type = HLSL_CLASS_MATRIX;
-        *dimx = min(t1->dimx, t2->dimx);
-        *dimy = min(t1->dimy, t2->dimy);
+        *dimx = min(t1->e.numeric.dimx, t2->e.numeric.dimx);
+        *dimy = min(t1->e.numeric.dimy, t2->e.numeric.dimy);
     }
     else
     {
-        if (t1->dimx * t1->dimy <= t2->dimx * t2->dimy)
+        if (t1->e.numeric.dimx * t1->e.numeric.dimy <= t2->e.numeric.dimx * t2->e.numeric.dimy)
         {
             *type = t1->class;
-            *dimx = t1->dimx;
-            *dimy = t1->dimy;
+            *dimx = t1->e.numeric.dimx;
+            *dimy = t1->e.numeric.dimy;
         }
         else
         {
             *type = t2->class;
-            *dimx = t2->dimx;
-            *dimy = t2->dimy;
+            *dimx = t2->e.numeric.dimx;
+            *dimy = t2->e.numeric.dimy;
         }
     }
 
@@ -1713,7 +1716,7 @@ static struct hlsl_ir_node *add_expr(struct hlsl_ctx *ctx, struct hlsl_block *bl
             return NULL;
         hlsl_init_simple_deref_from_var(&var_deref, var);
 
-        for (i = 0; i < type->dimy * type->dimx; ++i)
+        for (i = 0; i < type->e.numeric.dimy * type->e.numeric.dimx; ++i)
         {
             struct hlsl_ir_node *value, *cell_operands[HLSL_MAX_OPERANDS] = { NULL };
             struct hlsl_block store_block;
@@ -1816,7 +1819,7 @@ static struct hlsl_ir_node *add_unary_logical_expr(struct hlsl_ctx *ctx, struct
         return arg;
 
     bool_type = hlsl_get_numeric_type(ctx, arg->data_type->class, HLSL_TYPE_BOOL,
-            arg->data_type->dimx, arg->data_type->dimy);
+            arg->data_type->e.numeric.dimx, arg->data_type->e.numeric.dimy);
 
     if (!(args[0] = add_implicit_conversion(ctx, block, arg, bool_type, loc)))
         return NULL;
@@ -1979,11 +1982,11 @@ static struct hlsl_ir_node *add_binary_dot_expr(struct hlsl_ctx *ctx, struct hls
     }
 
     if (arg1->data_type->class == HLSL_CLASS_SCALAR)
-        dim = arg2->data_type->dimx;
+        dim = arg2->data_type->e.numeric.dimx;
     else if (arg2->data_type->class == HLSL_CLASS_SCALAR)
-        dim = arg1->data_type->dimx;
+        dim = arg1->data_type->e.numeric.dimx;
     else
-        dim = min(arg1->data_type->dimx, arg2->data_type->dimx);
+        dim = min(arg1->data_type->e.numeric.dimx, arg2->data_type->e.numeric.dimx);
 
     if (dim == 1)
         op = HLSL_OP2_MUL;
@@ -2187,8 +2190,8 @@ static bool add_assignment(struct hlsl_ctx *ctx, struct hlsl_block *block, struc
 
     if (hlsl_is_numeric_type(lhs_type))
     {
-        writemask = (1 << lhs_type->dimx) - 1;
-        width = lhs_type->dimx;
+        writemask = (1 << lhs_type->e.numeric.dimx) - 1;
+        width = lhs_type->e.numeric.dimx;
     }
 
     if (!(rhs = add_implicit_conversion(ctx, block, rhs, lhs_type, &rhs->loc)))
@@ -2275,13 +2278,13 @@ static bool add_assignment(struct hlsl_ctx *ctx, struct hlsl_block *block, struc
 
         dim_count = hlsl_sampler_dim_count(resource_type->sampler_dim);
 
-        if (width != resource_type->e.resource.format->dimx * resource_type->e.resource.format->dimy)
+        if (width != resource_type->e.resource.format->e.numeric.dimx * resource_type->e.resource.format->e.numeric.dimy)
             hlsl_error(ctx, &lhs->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_WRITEMASK,
                     "Resource store expressions must write to all components.");
 
         VKD3D_ASSERT(coords->data_type->class == HLSL_CLASS_VECTOR);
         VKD3D_ASSERT(coords->data_type->e.numeric.type == HLSL_TYPE_UINT);
-        VKD3D_ASSERT(coords->data_type->dimx == dim_count);
+        VKD3D_ASSERT(coords->data_type->e.numeric.dimx == dim_count);
 
         if (!(store = hlsl_new_resource_store(ctx, &resource_deref, coords, rhs, &lhs->loc)))
         {
@@ -2298,14 +2301,14 @@ static bool add_assignment(struct hlsl_ctx *ctx, struct hlsl_block *block, struc
 
         hlsl_init_deref_from_index_chain(ctx, &deref, lhs);
 
-        for (i = 0; i < lhs->data_type->dimy; ++i)
+        for (i = 0; i < lhs->data_type->e.numeric.dimy; ++i)
         {
-            for (j = 0; j < lhs->data_type->dimx; ++j)
+            for (j = 0; j < lhs->data_type->e.numeric.dimx; ++j)
             {
                 struct hlsl_ir_node *load;
                 struct hlsl_block store_block;
                 const unsigned int idx = i * 4 + j;
-                const unsigned int component = i * lhs->data_type->dimx + j;
+                const unsigned int component = i * lhs->data_type->e.numeric.dimx + j;
 
                 if (!(writemask & (1 << idx)))
                     continue;
@@ -2335,7 +2338,7 @@ static bool add_assignment(struct hlsl_ctx *ctx, struct hlsl_block *block, struc
 
         VKD3D_ASSERT(!matrix_writemask);
 
-        for (i = 0; i < mat->data_type->dimx; ++i)
+        for (i = 0; i < mat->data_type->e.numeric.dimx; ++i)
         {
             struct hlsl_ir_node *cell, *load, *store, *c;
             struct hlsl_deref deref;
@@ -3333,7 +3336,7 @@ static struct hlsl_ir_node *intrinsic_float_convert_arg(struct hlsl_ctx *ctx,
     if (!type_is_integer(type->e.numeric.type))
         return arg;
 
-    type = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_FLOAT, type->dimx, type->dimy);
+    type = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_FLOAT, type->e.numeric.dimx, type->e.numeric.dimy);
     return add_implicit_conversion(ctx, params->instrs, arg, type, loc);
 }
 
@@ -3372,13 +3375,13 @@ static struct hlsl_type *elementwise_intrinsic_get_common_type(struct hlsl_ctx *
         if (arg_type->class == HLSL_CLASS_VECTOR)
         {
             vectors = true;
-            dimx = min(dimx, arg_type->dimx);
+            dimx = min(dimx, arg_type->e.numeric.dimx);
         }
         else if (arg_type->class == HLSL_CLASS_MATRIX)
         {
             matrices = true;
-            dimx = min(dimx, arg_type->dimx);
-            dimy = min(dimy, arg_type->dimy);
+            dimx = min(dimx, arg_type->e.numeric.dimx);
+            dimy = min(dimy, arg_type->e.numeric.dimy);
         }
     }
 
@@ -3423,7 +3426,7 @@ static bool elementwise_intrinsic_float_convert_args(struct hlsl_ctx *ctx,
     if (!(type = elementwise_intrinsic_get_common_type(ctx, params, loc)))
         return false;
     if (type_is_integer(type->e.numeric.type))
-        type = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_FLOAT, type->dimx, type->dimy);
+        type = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_FLOAT, type->e.numeric.dimx, type->e.numeric.dimy);
 
     return convert_args(ctx, params, type, loc);
 }
@@ -3436,7 +3439,7 @@ static bool elementwise_intrinsic_uint_convert_args(struct hlsl_ctx *ctx,
     if (!(type = elementwise_intrinsic_get_common_type(ctx, params, loc)))
         return false;
 
-    type = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_UINT, type->dimx, type->dimy);
+    type = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_UINT, type->e.numeric.dimx, type->e.numeric.dimy);
 
     return convert_args(ctx, params, type, loc);
 }
@@ -3503,7 +3506,7 @@ static bool intrinsic_acos(struct hlsl_ctx *ctx,
 static struct hlsl_type *convert_numeric_type(const struct hlsl_ctx *ctx,
         const struct hlsl_type *type, enum hlsl_base_type base_type)
 {
-    return hlsl_get_numeric_type(ctx, type->class, base_type, type->dimx, type->dimy);
+    return hlsl_get_numeric_type(ctx, type->class, base_type, type->e.numeric.dimx, type->e.numeric.dimy);
 }
 
 static bool add_combine_components(struct hlsl_ctx *ctx, const struct parse_initializer *params,
@@ -4024,7 +4027,7 @@ static bool intrinsic_determinant(struct hlsl_ctx *ctx,
     if (!(arg = intrinsic_float_convert_arg(ctx, params, arg, loc)))
         return false;
 
-    dim = min(type->dimx, type->dimy);
+    dim = min(type->e.numeric.dimx, type->e.numeric.dimy);
     if (dim == 1)
         return hlsl_add_load_component(ctx, params->instrs, arg, 0, loc);
 
@@ -4108,7 +4111,7 @@ static bool intrinsic_dst(struct hlsl_ctx *ctx, const struct parse_initializer *
         return false;
     type = params->args[0]->data_type;
     if (!(type->class == HLSL_CLASS_SCALAR
-            || (type->class == HLSL_CLASS_VECTOR && type->dimx == 4)))
+            || (type->class == HLSL_CLASS_VECTOR && type->e.numeric.dimx == 4)))
     {
         struct vkd3d_string_buffer *string;
         if ((string = hlsl_type_to_string(ctx, type)))
@@ -4540,15 +4543,15 @@ static bool intrinsic_mul(struct hlsl_ctx *ctx,
     if (arg1->data_type->class == HLSL_CLASS_VECTOR)
     {
         vect_count++;
-        cast_type1 = hlsl_get_matrix_type(ctx, base, arg1->data_type->dimx, 1);
+        cast_type1 = hlsl_get_matrix_type(ctx, base, arg1->data_type->e.numeric.dimx, 1);
     }
     if (arg2->data_type->class == HLSL_CLASS_VECTOR)
     {
         vect_count++;
-        cast_type2 = hlsl_get_matrix_type(ctx, base, 1, arg2->data_type->dimx);
+        cast_type2 = hlsl_get_matrix_type(ctx, base, 1, arg2->data_type->e.numeric.dimx);
     }
 
-    matrix_type = hlsl_get_matrix_type(ctx, base, cast_type2->dimx, cast_type1->dimy);
+    matrix_type = hlsl_get_matrix_type(ctx, base, cast_type2->e.numeric.dimx, cast_type1->e.numeric.dimy);
 
     if (vect_count == 0)
     {
@@ -4556,12 +4559,12 @@ static bool intrinsic_mul(struct hlsl_ctx *ctx,
     }
     else if (vect_count == 1)
     {
-        VKD3D_ASSERT(matrix_type->dimx == 1 || matrix_type->dimy == 1);
-        ret_type = hlsl_get_vector_type(ctx, base, matrix_type->dimx * matrix_type->dimy);
+        VKD3D_ASSERT(matrix_type->e.numeric.dimx == 1 || matrix_type->e.numeric.dimy == 1);
+        ret_type = hlsl_get_vector_type(ctx, base, matrix_type->e.numeric.dimx * matrix_type->e.numeric.dimy);
     }
     else
     {
-        VKD3D_ASSERT(matrix_type->dimx == 1 && matrix_type->dimy == 1);
+        VKD3D_ASSERT(matrix_type->e.numeric.dimx == 1 && matrix_type->e.numeric.dimy == 1);
         ret_type = hlsl_get_scalar_type(ctx, base);
     }
 
@@ -4575,23 +4578,23 @@ static bool intrinsic_mul(struct hlsl_ctx *ctx,
         return false;
     hlsl_init_simple_deref_from_var(&var_deref, var);
 
-    for (i = 0; i < matrix_type->dimx; ++i)
+    for (i = 0; i < matrix_type->e.numeric.dimx; ++i)
     {
-        for (j = 0; j < matrix_type->dimy; ++j)
+        for (j = 0; j < matrix_type->e.numeric.dimy; ++j)
         {
             struct hlsl_ir_node *instr = NULL;
             struct hlsl_block block;
 
-            for (k = 0; k < cast_type1->dimx && k < cast_type2->dimy; ++k)
+            for (k = 0; k < cast_type1->e.numeric.dimx && k < cast_type2->e.numeric.dimy; ++k)
             {
                 struct hlsl_ir_node *value1, *value2, *mul;
 
                 if (!(value1 = hlsl_add_load_component(ctx, params->instrs,
-                        cast1, j * cast1->data_type->dimx + k, loc)))
+                        cast1, j * cast1->data_type->e.numeric.dimx + k, loc)))
                     return false;
 
                 if (!(value2 = hlsl_add_load_component(ctx, params->instrs,
-                        cast2, k * cast2->data_type->dimx + i, loc)))
+                        cast2, k * cast2->data_type->e.numeric.dimx + i, loc)))
                     return false;
 
                 if (!(mul = add_binary_arithmetic_expr(ctx, params->instrs, HLSL_OP2_MUL, value1, value2, loc)))
@@ -4608,7 +4611,7 @@ static bool intrinsic_mul(struct hlsl_ctx *ctx,
                 }
             }
 
-            if (!hlsl_new_store_component(ctx, &block, &var_deref, j * matrix_type->dimx + i, instr))
+            if (!hlsl_new_store_component(ctx, &block, &var_deref, j * matrix_type->e.numeric.dimx + i, instr))
                 return false;
             hlsl_block_add_block(params->instrs, &block);
         }
@@ -4801,7 +4804,7 @@ static bool intrinsic_sign(struct hlsl_ctx *ctx,
     static const struct hlsl_constant_value zero_value;
 
     struct hlsl_type *int_type = hlsl_get_numeric_type(ctx, arg->data_type->class, HLSL_TYPE_INT,
-            arg->data_type->dimx, arg->data_type->dimy);
+            arg->data_type->e.numeric.dimx, arg->data_type->e.numeric.dimy);
 
     if (!(zero = hlsl_new_constant(ctx, hlsl_get_scalar_type(ctx, arg->data_type->e.numeric.type), &zero_value, loc)))
         return false;
@@ -5255,22 +5258,23 @@ static bool intrinsic_transpose(struct hlsl_ctx *ctx,
         return true;
     }
 
-    mat_type = hlsl_get_matrix_type(ctx, arg_type->e.numeric.type, arg_type->dimy, arg_type->dimx);
+    mat_type = hlsl_get_matrix_type(ctx, arg_type->e.numeric.type, arg_type->e.numeric.dimy, arg_type->e.numeric.dimx);
 
     if (!(var = hlsl_new_synthetic_var(ctx, "transpose", mat_type, loc)))
         return false;
     hlsl_init_simple_deref_from_var(&var_deref, var);
 
-    for (i = 0; i < arg_type->dimx; ++i)
+    for (i = 0; i < arg_type->e.numeric.dimx; ++i)
     {
-        for (j = 0; j < arg_type->dimy; ++j)
+        for (j = 0; j < arg_type->e.numeric.dimy; ++j)
         {
             struct hlsl_block block;
 
-            if (!(load = hlsl_add_load_component(ctx, params->instrs, arg, j * arg->data_type->dimx + i, loc)))
+            if (!(load = hlsl_add_load_component(ctx, params->instrs, arg,
+                    j * arg->data_type->e.numeric.dimx + i, loc)))
                 return false;
 
-            if (!hlsl_new_store_component(ctx, &block, &var_deref, i * var->data_type->dimx + j, load))
+            if (!hlsl_new_store_component(ctx, &block, &var_deref, i * var->data_type->e.numeric.dimx + j, load))
                 return false;
             hlsl_block_add_block(params->instrs, &block);
         }
@@ -5300,7 +5304,8 @@ static bool intrinsic_d3dcolor_to_ubyte4(struct hlsl_ctx *ctx,
     struct hlsl_ir_node *arg = params->args[0], *ret, *c, *swizzle;
     struct hlsl_type *arg_type = arg->data_type;
 
-    if (arg_type->class != HLSL_CLASS_SCALAR && !(arg_type->class == HLSL_CLASS_VECTOR && arg_type->dimx == 4))
+    if (arg_type->class != HLSL_CLASS_SCALAR && !(arg_type->class == HLSL_CLASS_VECTOR
+            && arg_type->e.numeric.dimx == 4))
     {
         struct vkd3d_string_buffer *string;
 
@@ -5663,6 +5668,7 @@ static bool add_ternary(struct hlsl_ctx *ctx, struct hlsl_block *block,
             hlsl_error(ctx, &cond->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_TYPE,
                     "Ternary condition type '%s' is not numeric.", string->buffer);
         hlsl_release_string_buffer(ctx, string);
+        return false;
     }
 
     if (first->data_type->class <= HLSL_CLASS_LAST_NUMERIC
@@ -5671,21 +5677,22 @@ static bool add_ternary(struct hlsl_ctx *ctx, struct hlsl_block *block,
         if (!(common_type = get_common_numeric_type(ctx, first, second, &first->loc)))
             return false;
 
-        if (cond_type->dimx == 1 && cond_type->dimy == 1)
+        if (cond_type->e.numeric.dimx == 1 && cond_type->e.numeric.dimy == 1)
         {
             cond_type = hlsl_get_numeric_type(ctx, common_type->class,
-                    HLSL_TYPE_BOOL, common_type->dimx, common_type->dimy);
+                    HLSL_TYPE_BOOL, common_type->e.numeric.dimx, common_type->e.numeric.dimy);
             if (!(cond = add_implicit_conversion(ctx, block, cond, cond_type, &cond->loc)))
                 return false;
         }
         else
         {
-            if (common_type->dimx == 1 && common_type->dimy == 1)
+            if (common_type->e.numeric.dimx == 1 && common_type->e.numeric.dimy == 1)
             {
                 common_type = hlsl_get_numeric_type(ctx, cond_type->class,
-                        common_type->e.numeric.type, cond_type->dimx, cond_type->dimy);
+                        common_type->e.numeric.type, cond_type->e.numeric.dimx, cond_type->e.numeric.dimy);
             }
-            else if (cond_type->dimx != common_type->dimx || cond_type->dimy != common_type->dimy)
+            else if (cond_type->e.numeric.dimx != common_type->e.numeric.dimx
+                    || cond_type->e.numeric.dimy != common_type->e.numeric.dimy)
             {
                 /* This condition looks wrong but is correct.
                 * floatN is compatible with float1xN, but not with floatNx1. */
@@ -5703,7 +5710,7 @@ static bool add_ternary(struct hlsl_ctx *ctx, struct hlsl_block *block,
             }
 
             cond_type = hlsl_get_numeric_type(ctx, common_type->class, HLSL_TYPE_BOOL,
-                    common_type->dimx, common_type->dimy);
+                    common_type->e.numeric.dimx, common_type->e.numeric.dimy);
             if (!(cond = add_implicit_conversion(ctx, block, cond, cond_type, &cond->loc)))
                 return false;
         }
@@ -5731,7 +5738,7 @@ static bool add_ternary(struct hlsl_ctx *ctx, struct hlsl_block *block,
         }
 
         cond_type = hlsl_get_numeric_type(ctx, cond_type->class, HLSL_TYPE_BOOL,
-                cond_type->dimx, cond_type->dimy);
+                cond_type->e.numeric.dimx, cond_type->e.numeric.dimy);
         if (!(cond = add_implicit_conversion(ctx, block, cond, cond_type, &cond->loc)))
             return false;
 
@@ -6103,7 +6110,7 @@ static bool add_gather_method_call(struct hlsl_ctx *ctx, struct hlsl_block *bloc
         return false;
     }
 
-    if (read_channel >= object_type->e.resource.format->dimx)
+    if (read_channel >= object_type->e.resource.format->e.numeric.dimx)
     {
         hlsl_error(ctx, loc, VKD3D_SHADER_ERROR_HLSL_INVALID_TYPE,
                 "Method %s() requires at least %u channels.", name, read_channel + 1);
diff --git a/libs/vkd3d/libs/vkd3d-shader/hlsl_codegen.c b/libs/vkd3d/libs/vkd3d-shader/hlsl_codegen.c
index 4ccbed78f38..c666599b342 100644
--- a/libs/vkd3d/libs/vkd3d-shader/hlsl_codegen.c
+++ b/libs/vkd3d/libs/vkd3d-shader/hlsl_codegen.c
@@ -20,9 +20,13 @@
 
 #include "hlsl.h"
 #include "vkd3d_shader_private.h"
+#include "d3dcommon.h"
 #include <stdio.h>
 #include <math.h>
 
+/* The shift that corresponds to the D3D_SIF_TEXTURE_COMPONENTS mask. */
+#define VKD3D_SM4_SIF_TEXTURE_COMPONENTS_SHIFT 2
+
 /* TODO: remove when no longer needed, only used for new_offset_instr_from_deref() */
 static struct hlsl_ir_node *new_offset_from_path_index(struct hlsl_ctx *ctx, struct hlsl_block *block,
         struct hlsl_type *type, struct hlsl_ir_node *base_offset, struct hlsl_ir_node *idx,
@@ -270,7 +274,7 @@ static bool types_are_semantic_equivalent(struct hlsl_ctx *ctx, const struct hls
     if (ctx->profile->major_version < 4)
         return true;
 
-    if (type1->dimx != type2->dimx)
+    if (type1->e.numeric.dimx != type2->e.numeric.dimx)
         return false;
 
     return base_type_get_semantic_equivalent(type1->e.numeric.type)
@@ -292,6 +296,9 @@ static struct hlsl_ir_var *add_semantic_var(struct hlsl_ctx *ctx, struct hlsl_ir
     {
         if (!ascii_strcasecmp(ext_var->name, new_name))
         {
+            VKD3D_ASSERT(ext_var->data_type->class <= HLSL_CLASS_VECTOR);
+            VKD3D_ASSERT(type->class <= HLSL_CLASS_VECTOR);
+
             if (output)
             {
                 if (index >= semantic->reported_duplicated_output_next_index)
@@ -1032,7 +1039,7 @@ static bool lower_calls(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, void *
 static struct hlsl_ir_node *add_zero_mipmap_level(struct hlsl_ctx *ctx, struct hlsl_ir_node *index,
         const struct vkd3d_shader_location *loc)
 {
-    unsigned int dim_count = index->data_type->dimx;
+    unsigned int dim_count = index->data_type->e.numeric.dimx;
     struct hlsl_ir_node *store, *zero;
     struct hlsl_ir_load *coords_load;
     struct hlsl_deref coords_deref;
@@ -1089,12 +1096,12 @@ static bool lower_matrix_swizzles(struct hlsl_ctx *ctx, struct hlsl_ir_node *ins
         return false;
     hlsl_init_simple_deref_from_var(&var_deref, var);
 
-    for (i = 0; i < instr->data_type->dimx; ++i)
+    for (i = 0; i < instr->data_type->e.numeric.dimx; ++i)
     {
         struct hlsl_block store_block;
         struct hlsl_ir_node *load;
 
-        k = swizzle->u.matrix.components[i].y * matrix_type->dimx + swizzle->u.matrix.components[i].x;
+        k = swizzle->u.matrix.components[i].y * matrix_type->e.numeric.dimx + swizzle->u.matrix.components[i].x;
 
         if (!(load = hlsl_add_load_component(ctx, block, swizzle->val.node, k, &instr->loc)))
             return false;
@@ -1139,7 +1146,7 @@ static bool lower_index_loads(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr,
 
         VKD3D_ASSERT(coords->data_type->class == HLSL_CLASS_VECTOR);
         VKD3D_ASSERT(coords->data_type->e.numeric.type == HLSL_TYPE_UINT);
-        VKD3D_ASSERT(coords->data_type->dimx == dim_count);
+        VKD3D_ASSERT(coords->data_type->e.numeric.dimx == dim_count);
 
         if (!(coords = add_zero_mipmap_level(ctx, coords, &instr->loc)))
             return false;
@@ -1175,7 +1182,7 @@ static bool lower_index_loads(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr,
             return false;
         hlsl_init_simple_deref_from_var(&row_deref, var);
 
-        for (i = 0; i < mat->data_type->dimx; ++i)
+        for (i = 0; i < mat->data_type->e.numeric.dimx; ++i)
         {
             struct hlsl_ir_node *c;
 
@@ -1224,7 +1231,7 @@ static bool lower_broadcasts(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, s
     src_type = cast->operands[0].node->data_type;
     dst_type = cast->node.data_type;
 
-    if (src_type->class <= HLSL_CLASS_VECTOR && dst_type->class <= HLSL_CLASS_VECTOR && src_type->dimx == 1)
+    if (src_type->class <= HLSL_CLASS_VECTOR && dst_type->class <= HLSL_CLASS_VECTOR && src_type->e.numeric.dimx == 1)
     {
         struct hlsl_ir_node *new_cast, *swizzle;
 
@@ -1235,9 +1242,10 @@ static bool lower_broadcasts(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, s
             return false;
         hlsl_block_add_instr(block, new_cast);
 
-        if (dst_type->dimx != 1)
+        if (dst_type->e.numeric.dimx != 1)
         {
-            if (!(swizzle = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X), dst_type->dimx, new_cast, &cast->node.loc)))
+            if (!(swizzle = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X),
+                    dst_type->e.numeric.dimx, new_cast, &cast->node.loc)))
                 return false;
             hlsl_block_add_instr(block, swizzle);
         }
@@ -2092,10 +2100,10 @@ static enum validation_result validate_component_index_range_from_deref(struct h
         switch (type->class)
         {
             case HLSL_CLASS_VECTOR:
-                if (idx >= type->dimx)
+                if (idx >= type->e.numeric.dimx)
                 {
                     hlsl_error(ctx, &path_node->loc, VKD3D_SHADER_ERROR_HLSL_OFFSET_OUT_OF_BOUNDS,
-                            "Vector index is out of bounds. %u/%u", idx, type->dimx);
+                            "Vector index is out of bounds. %u/%u", idx, type->e.numeric.dimx);
                     return DEREF_VALIDATION_OUT_OF_BOUNDS;
                 }
                 break;
@@ -2226,7 +2234,7 @@ static bool validate_dereferences(struct hlsl_ctx *ctx, struct hlsl_ir_node *ins
 
 static bool is_vec1(const struct hlsl_type *type)
 {
-    return (type->class == HLSL_CLASS_SCALAR) || (type->class == HLSL_CLASS_VECTOR && type->dimx == 1);
+    return (type->class == HLSL_CLASS_SCALAR) || (type->class == HLSL_CLASS_VECTOR && type->e.numeric.dimx == 1);
 }
 
 static bool fold_redundant_casts(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, void *context)
@@ -2403,18 +2411,20 @@ static bool lower_narrowing_casts(struct hlsl_ctx *ctx, struct hlsl_ir_node *ins
     src_type = cast->operands[0].node->data_type;
     dst_type = cast->node.data_type;
 
-    if (src_type->class <= HLSL_CLASS_VECTOR && dst_type->class <= HLSL_CLASS_VECTOR && dst_type->dimx < src_type->dimx)
+    if (src_type->class <= HLSL_CLASS_VECTOR && dst_type->class <= HLSL_CLASS_VECTOR
+            && dst_type->e.numeric.dimx < src_type->e.numeric.dimx)
     {
         struct hlsl_ir_node *new_cast, *swizzle;
 
-        dst_vector_type = hlsl_get_vector_type(ctx, dst_type->e.numeric.type, src_type->dimx);
+        dst_vector_type = hlsl_get_vector_type(ctx, dst_type->e.numeric.type, src_type->e.numeric.dimx);
         /* We need to preserve the cast since it might be doing more than just
          * narrowing the vector. */
         if (!(new_cast = hlsl_new_cast(ctx, cast->operands[0].node, dst_vector_type, &cast->node.loc)))
             return false;
         hlsl_block_add_instr(block, new_cast);
 
-        if (!(swizzle = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, Y, Z, W), dst_type->dimx, new_cast, &cast->node.loc)))
+        if (!(swizzle = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, Y, Z, W),
+                dst_type->e.numeric.dimx, new_cast, &cast->node.loc)))
             return false;
         hlsl_block_add_instr(block, swizzle);
 
@@ -2441,10 +2451,11 @@ static bool fold_swizzle_chains(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr
         uint32_t combined_swizzle;
 
         combined_swizzle = hlsl_combine_swizzles(hlsl_ir_swizzle(next_instr)->u.vector,
-                swizzle->u.vector, instr->data_type->dimx);
+                swizzle->u.vector, instr->data_type->e.numeric.dimx);
         next_instr = hlsl_ir_swizzle(next_instr)->val.node;
 
-        if (!(new_swizzle = hlsl_new_swizzle(ctx, combined_swizzle, instr->data_type->dimx, next_instr, &instr->loc)))
+        if (!(new_swizzle = hlsl_new_swizzle(ctx, combined_swizzle,
+                instr->data_type->e.numeric.dimx, next_instr, &instr->loc)))
             return false;
 
         list_add_before(&instr->entry, &new_swizzle->entry);
@@ -2464,10 +2475,10 @@ static bool remove_trivial_swizzles(struct hlsl_ctx *ctx, struct hlsl_ir_node *i
         return false;
     swizzle = hlsl_ir_swizzle(instr);
 
-    if (instr->data_type->dimx != swizzle->val.node->data_type->dimx)
+    if (instr->data_type->e.numeric.dimx != swizzle->val.node->data_type->e.numeric.dimx)
         return false;
 
-    for (i = 0; i < instr->data_type->dimx; ++i)
+    for (i = 0; i < instr->data_type->e.numeric.dimx; ++i)
         if (hlsl_swizzle_get_component(swizzle->u.vector, i) != i)
             return false;
 
@@ -2628,6 +2639,7 @@ static bool lower_nonconstant_vector_derefs(struct hlsl_ctx *ctx, struct hlsl_ir
     if (type->class == HLSL_CLASS_VECTOR && idx->type != HLSL_IR_CONSTANT)
     {
         struct hlsl_ir_node *eq, *swizzle, *dot, *c, *operands[HLSL_MAX_OPERANDS] = {0};
+        unsigned int width = type->e.numeric.dimx;
         struct hlsl_constant_value value;
         struct hlsl_ir_load *vector_load;
         enum hlsl_ir_expr_op op;
@@ -2636,7 +2648,7 @@ static bool lower_nonconstant_vector_derefs(struct hlsl_ctx *ctx, struct hlsl_ir
             return false;
         hlsl_block_add_instr(block, &vector_load->node);
 
-        if (!(swizzle = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X), type->dimx, idx, &instr->loc)))
+        if (!(swizzle = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X), width, idx, &instr->loc)))
             return false;
         hlsl_block_add_instr(block, swizzle);
 
@@ -2644,14 +2656,14 @@ static bool lower_nonconstant_vector_derefs(struct hlsl_ctx *ctx, struct hlsl_ir
         value.u[1].u = 1;
         value.u[2].u = 2;
         value.u[3].u = 3;
-        if (!(c = hlsl_new_constant(ctx, hlsl_get_vector_type(ctx, HLSL_TYPE_UINT, type->dimx), &value, &instr->loc)))
+        if (!(c = hlsl_new_constant(ctx, hlsl_get_vector_type(ctx, HLSL_TYPE_UINT, width), &value, &instr->loc)))
             return false;
         hlsl_block_add_instr(block, c);
 
         operands[0] = swizzle;
         operands[1] = c;
         if (!(eq = hlsl_new_expr(ctx, HLSL_OP2_EQUAL, operands,
-                hlsl_get_vector_type(ctx, HLSL_TYPE_BOOL, type->dimx), &instr->loc)))
+                hlsl_get_vector_type(ctx, HLSL_TYPE_BOOL, width), &instr->loc)))
             return false;
         hlsl_block_add_instr(block, eq);
 
@@ -2660,7 +2672,7 @@ static bool lower_nonconstant_vector_derefs(struct hlsl_ctx *ctx, struct hlsl_ir
         hlsl_block_add_instr(block, eq);
 
         op = HLSL_OP2_DOT;
-        if (type->dimx == 1)
+        if (width == 1)
             op = type->e.numeric.type == HLSL_TYPE_BOOL ? HLSL_OP2_LOGIC_AND : HLSL_OP2_MUL;
 
         /* Note: We may be creating a DOT for bool vectors here, which we need to lower to
@@ -2787,7 +2799,8 @@ static bool lower_nonconstant_array_loads(struct hlsl_ctx *ctx, struct hlsl_ir_n
             return false;
         hlsl_block_add_instr(block, equals);
 
-        if (!(equals = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X), var->data_type->dimx, equals, &cut_index->loc)))
+        if (!(equals = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X),
+                var->data_type->e.numeric.dimx, equals, &cut_index->loc)))
             return false;
         hlsl_block_add_instr(block, equals);
 
@@ -3176,7 +3189,7 @@ static bool lower_dot(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct h
     arg2 = expr->operands[1].node;
     if (expr->op != HLSL_OP2_DOT)
         return false;
-    if (arg1->data_type->dimx != 2)
+    if (arg1->data_type->e.numeric.dimx != 2)
         return false;
 
     if (ctx->profile->type == VKD3D_SHADER_TYPE_PIXEL)
@@ -3200,11 +3213,13 @@ static bool lower_dot(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct h
             return false;
         hlsl_block_add_instr(block, mul);
 
-        if (!(add_x = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X), instr->data_type->dimx, mul, &expr->node.loc)))
+        if (!(add_x = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(X, X, X, X),
+                instr->data_type->e.numeric.dimx, mul, &expr->node.loc)))
             return false;
         hlsl_block_add_instr(block, add_x);
 
-        if (!(add_y = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(Y, Y, Y, Y), instr->data_type->dimx, mul, &expr->node.loc)))
+        if (!(add_y = hlsl_new_swizzle(ctx, HLSL_SWIZZLE(Y, Y, Y, Y),
+                instr->data_type->e.numeric.dimx, mul, &expr->node.loc)))
             return false;
         hlsl_block_add_instr(block, add_y);
 
@@ -3368,7 +3383,7 @@ static bool lower_trig(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct
     type = arg->data_type;
 
     /* Reduce the range of the input angles to [-pi, pi]. */
-    for (i = 0; i < type->dimx; ++i)
+    for (i = 0; i < type->e.numeric.dimx; ++i)
     {
         half_value.u[i].f = 0.5;
         two_pi_value.u[i].f = 2.0 * M_PI;
@@ -3396,7 +3411,7 @@ static bool lower_trig(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct
         return false;
     hlsl_block_add_instr(block, reduced);
 
-    if (type->dimx == 1)
+    if (type->e.numeric.dimx == 1)
     {
         if (!(sincos = hlsl_new_unary_expr(ctx, op, reduced, &instr->loc)))
             return false;
@@ -3409,7 +3424,7 @@ static bool lower_trig(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct
         struct hlsl_deref var_deref;
         struct hlsl_ir_load *var_load;
 
-        for (i = 0; i < type->dimx; ++i)
+        for (i = 0; i < type->e.numeric.dimx; ++i)
         {
             uint32_t s = hlsl_swizzle_from_writemask(1 << i);
 
@@ -3422,7 +3437,7 @@ static bool lower_trig(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct
             return false;
         hlsl_init_simple_deref_from_var(&var_deref, var);
 
-        for (i = 0; i < type->dimx; ++i)
+        for (i = 0; i < type->e.numeric.dimx; ++i)
         {
             struct hlsl_block store_block;
 
@@ -3458,7 +3473,7 @@ static bool lower_logic_not(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, st
         return false;
 
     arg = expr->operands[0].node;
-    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, arg->data_type->dimx);
+    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, arg->data_type->e.numeric.dimx);
 
     /* If this is happens, it means we failed to cast the argument to boolean somewhere. */
     VKD3D_ASSERT(arg->data_type->e.numeric.type == HLSL_TYPE_BOOL);
@@ -3520,7 +3535,7 @@ static bool lower_ternary(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, stru
     VKD3D_ASSERT(cond->data_type->e.numeric.type == HLSL_TYPE_BOOL);
 
     type = hlsl_get_numeric_type(ctx, instr->data_type->class, HLSL_TYPE_FLOAT,
-            instr->data_type->dimx, instr->data_type->dimy);
+            instr->data_type->e.numeric.dimx, instr->data_type->e.numeric.dimy);
 
     if (!(float_cond = hlsl_new_cast(ctx, cond, type, &instr->loc)))
         return false;
@@ -3604,7 +3619,7 @@ static bool lower_comparison_operators(struct hlsl_ctx *ctx, struct hlsl_ir_node
 
     arg1 = expr->operands[0].node;
     arg2 = expr->operands[1].node;
-    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->dimx);
+    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->e.numeric.dimx);
 
     if (!(arg1_cast = hlsl_new_cast(ctx, arg1, float_type, &instr->loc)))
         return false;
@@ -3730,7 +3745,7 @@ static bool lower_slt(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct h
 
     arg1 = expr->operands[0].node;
     arg2 = expr->operands[1].node;
-    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->dimx);
+    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->e.numeric.dimx);
 
     if (!(arg1_cast = hlsl_new_cast(ctx, arg1, float_type, &instr->loc)))
         return false;
@@ -3790,7 +3805,7 @@ static bool lower_cmp(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, struct h
     if (expr->op != HLSL_OP3_CMP)
         return false;
 
-    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->dimx);
+    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->e.numeric.dimx);
 
     for (i = 0; i < 3; ++i)
     {
@@ -3860,7 +3875,7 @@ static bool lower_casts_to_bool(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr
         return false;
 
     /* Narrowing casts should have already been lowered. */
-    VKD3D_ASSERT(type->dimx == arg_type->dimx);
+    VKD3D_ASSERT(type->e.numeric.dimx == arg_type->e.numeric.dimx);
 
     zero = hlsl_new_constant(ctx, arg_type, &zero_value, &instr->loc);
     if (!zero)
@@ -3886,7 +3901,8 @@ struct hlsl_ir_node *hlsl_add_conditional(struct hlsl_ctx *ctx, struct hlsl_bloc
 
     if (cond_type->e.numeric.type != HLSL_TYPE_BOOL)
     {
-        cond_type = hlsl_get_numeric_type(ctx, cond_type->class, HLSL_TYPE_BOOL, cond_type->dimx, cond_type->dimy);
+        cond_type = hlsl_get_numeric_type(ctx, cond_type->class, HLSL_TYPE_BOOL,
+                cond_type->e.numeric.dimx, cond_type->e.numeric.dimy);
 
         if (!(condition = hlsl_new_cast(ctx, condition, cond_type, &condition->loc)))
             return NULL;
@@ -3922,13 +3938,13 @@ static bool lower_int_division(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr,
         return false;
     if (type->e.numeric.type != HLSL_TYPE_INT)
         return false;
-    utype = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_UINT, type->dimx, type->dimy);
+    utype = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_UINT, type->e.numeric.dimx, type->e.numeric.dimy);
 
     if (!(xor = hlsl_new_binary_expr(ctx, HLSL_OP2_BIT_XOR, arg1, arg2)))
         return false;
     hlsl_block_add_instr(block, xor);
 
-    for (i = 0; i < type->dimx; ++i)
+    for (i = 0; i < type->e.numeric.dimx; ++i)
         high_bit_value.u[i].u = 0x80000000;
     if (!(high_bit = hlsl_new_constant(ctx, type, &high_bit_value, &instr->loc)))
         return false;
@@ -3988,9 +4004,9 @@ static bool lower_int_modulus(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr,
         return false;
     if (type->e.numeric.type != HLSL_TYPE_INT)
         return false;
-    utype = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_UINT, type->dimx, type->dimy);
+    utype = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_UINT, type->e.numeric.dimx, type->e.numeric.dimy);
 
-    for (i = 0; i < type->dimx; ++i)
+    for (i = 0; i < type->e.numeric.dimx; ++i)
         high_bit_value.u[i].u = 0x80000000;
     if (!(high_bit = hlsl_new_constant(ctx, type, &high_bit_value, &instr->loc)))
         return false;
@@ -4081,8 +4097,8 @@ static bool lower_int_dot(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, stru
     {
         arg1 = expr->operands[0].node;
         arg2 = expr->operands[1].node;
-        VKD3D_ASSERT(arg1->data_type->dimx == arg2->data_type->dimx);
-        dimx = arg1->data_type->dimx;
+        VKD3D_ASSERT(arg1->data_type->e.numeric.dimx == arg2->data_type->e.numeric.dimx);
+        dimx = arg1->data_type->e.numeric.dimx;
         is_bool = type->e.numeric.type == HLSL_TYPE_BOOL;
 
         if (!(mult = hlsl_new_binary_expr(ctx, is_bool ? HLSL_OP2_LOGIC_AND : HLSL_OP2_MUL, arg1, arg2)))
@@ -4131,7 +4147,7 @@ static bool lower_float_modulus(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr
         return false;
     if (type->e.numeric.type != HLSL_TYPE_FLOAT)
         return false;
-    btype = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_BOOL, type->dimx, type->dimy);
+    btype = hlsl_get_numeric_type(ctx, type->class, HLSL_TYPE_BOOL, type->e.numeric.dimx, type->e.numeric.dimy);
 
     if (!(mul1 = hlsl_new_binary_expr(ctx, HLSL_OP2_MUL, arg2, arg1)))
         return false;
@@ -4153,7 +4169,7 @@ static bool lower_float_modulus(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr
     if (!(cond = hlsl_add_conditional(ctx, block, ge, arg2, neg2)))
         return false;
 
-    for (i = 0; i < type->dimx; ++i)
+    for (i = 0; i < type->e.numeric.dimx; ++i)
         one_value.u[i].f = 1.0f;
     if (!(one = hlsl_new_constant(ctx, type, &one_value, &instr->loc)))
         return false;
@@ -4211,7 +4227,7 @@ static bool lower_nonfloat_exprs(struct hlsl_ctx *ctx, struct hlsl_ir_node *inst
                 if (!arg)
                     continue;
 
-                float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, arg->data_type->dimx);
+                float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, arg->data_type->e.numeric.dimx);
                 if (!(arg_cast = hlsl_new_cast(ctx, arg, float_type, &instr->loc)))
                     return false;
                 hlsl_block_add_instr(block, arg_cast);
@@ -4219,7 +4235,7 @@ static bool lower_nonfloat_exprs(struct hlsl_ctx *ctx, struct hlsl_ir_node *inst
                 operands[i] = arg_cast;
             }
 
-            float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->dimx);
+            float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, instr->data_type->e.numeric.dimx);
             if (!(float_expr = hlsl_new_expr(ctx, expr->op, operands, float_type, &instr->loc)))
                 return false;
             hlsl_block_add_instr(block, float_expr);
@@ -4260,7 +4276,8 @@ static bool lower_discard_neg(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr,
 
     operands[0] = jump->condition.node;
     operands[1] = zero;
-    cmp_type = hlsl_get_numeric_type(ctx, arg_type->class, HLSL_TYPE_BOOL, arg_type->dimx, arg_type->dimy);
+    cmp_type = hlsl_get_numeric_type(ctx, arg_type->class, HLSL_TYPE_BOOL,
+            arg_type->e.numeric.dimx, arg_type->e.numeric.dimy);
     if (!(cmp = hlsl_new_expr(ctx, HLSL_OP2_LESS, operands, cmp_type, &instr->loc)))
         return false;
     hlsl_block_add_instr(&block, cmp);
@@ -4304,7 +4321,7 @@ static bool lower_discard_nz(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, v
         return false;
 
     cond = jump->condition.node;
-    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, cond->data_type->dimx);
+    float_type = hlsl_get_vector_type(ctx, HLSL_TYPE_FLOAT, cond->data_type->e.numeric.dimx);
 
     hlsl_block_init(&block);
 
@@ -4900,7 +4917,8 @@ static struct hlsl_reg allocate_numeric_registers_for_type(struct hlsl_ctx *ctx,
     /* FIXME: We could potentially pack structs or arrays more efficiently... */
 
     if (type->class <= HLSL_CLASS_VECTOR)
-        return allocate_register(ctx, allocator, first_write, last_read, type->dimx, type->dimx, 0, false, false);
+        return allocate_register(ctx, allocator, first_write, last_read,
+                type->e.numeric.dimx, type->e.numeric.dimx, 0, false, false);
     else
         return allocate_range(ctx, allocator, first_write, last_read, reg_size, 0, false);
 }
@@ -5227,13 +5245,13 @@ static void allocate_const_registers_recurse(struct hlsl_ctx *ctx,
                 TRACE("Allocated constant @%u to %s.\n", instr->index, debug_register('c', constant->reg, type));
 
                 VKD3D_ASSERT(hlsl_is_numeric_type(type));
-                VKD3D_ASSERT(type->dimy == 1);
+                VKD3D_ASSERT(type->e.numeric.dimy == 1);
                 VKD3D_ASSERT(constant->reg.writemask);
 
                 for (x = 0, i = 0; x < 4; ++x)
                 {
                     const union hlsl_constant_value_component *value;
-                    float f;
+                    float f = 0;
 
                     if (!(constant->reg.writemask & (1u << x)))
                         continue;
@@ -5261,9 +5279,6 @@ static void allocate_const_registers_recurse(struct hlsl_ctx *ctx,
                         case HLSL_TYPE_DOUBLE:
                             FIXME("Double constant.\n");
                             return;
-
-                        default:
-                            vkd3d_unreachable();
                     }
 
                     record_constant(ctx, constant->reg.id * 4 + x, f, &constant->node.loc);
@@ -5608,13 +5623,13 @@ static void allocate_semantic_register(struct hlsl_ctx *ctx, struct hlsl_ir_var
     {
         int mode = (ctx->profile->major_version < 4)
                 ? 0 : sm4_get_interpolation_mode(var->data_type, var->storage_modifiers);
-        unsigned int reg_size = optimize ? var->data_type->dimx : 4;
+        unsigned int reg_size = optimize ? var->data_type->e.numeric.dimx : 4;
 
         if (special_interpolation)
             mode = VKD3DSIM_NONE;
 
         var->regs[HLSL_REGSET_NUMERIC] = allocate_register(ctx, allocator, 1, UINT_MAX,
-                reg_size, var->data_type->dimx, mode, var->force_align, vip_allocation);
+                reg_size, var->data_type->e.numeric.dimx, mode, var->force_align, vip_allocation);
 
         TRACE("Allocated %s to %s (mode %d).\n", var->name, debug_register(output ? 'o' : 'v',
                 var->regs[HLSL_REGSET_NUMERIC], var->data_type), mode);
@@ -6068,7 +6083,7 @@ bool hlsl_component_index_range_from_deref(struct hlsl_ctx *ctx, const struct hl
         switch (type->class)
         {
             case HLSL_CLASS_VECTOR:
-                if (idx >= type->dimx)
+                if (idx >= type->e.numeric.dimx)
                     return false;
                 *start += idx;
                 break;
@@ -6077,9 +6092,9 @@ bool hlsl_component_index_range_from_deref(struct hlsl_ctx *ctx, const struct hl
                 if (idx >= hlsl_type_major_size(type))
                     return false;
                 if (hlsl_type_is_row_major(type))
-                    *start += idx * type->dimx;
+                    *start += idx * type->e.numeric.dimx;
                 else
-                    *start += idx * type->dimy;
+                    *start += idx * type->e.numeric.dimy;
                 break;
 
             case HLSL_CLASS_ARRAY:
@@ -6668,8 +6683,8 @@ void hlsl_run_const_passes(struct hlsl_ctx *ctx, struct hlsl_block *body)
 static void generate_vsir_signature_entry(struct hlsl_ctx *ctx, struct vsir_program *program,
         struct shader_signature *signature, bool output, bool is_patch_constant_func, struct hlsl_ir_var *var)
 {
+    enum vkd3d_shader_component_type component_type = VKD3D_SHADER_COMPONENT_VOID;
     enum vkd3d_shader_sysval_semantic sysval = VKD3D_SHADER_SV_NONE;
-    enum vkd3d_shader_component_type component_type;
     unsigned int register_index, mask, use_mask;
     const char *name = var->semantic.name;
     enum vkd3d_shader_register_type type;
@@ -6689,7 +6704,7 @@ static void generate_vsir_signature_entry(struct hlsl_ctx *ctx, struct vsir_prog
         if (sm4_register_from_semantic_name(&program->shader_version, var->semantic.name, output, &type, &has_idx))
         {
             register_index = has_idx ? var->semantic.index : ~0u;
-            mask = (1u << var->data_type->dimx) - 1;
+            mask = (1u << var->data_type->e.numeric.dimx) - 1;
         }
         else
         {
@@ -6716,12 +6731,11 @@ static void generate_vsir_signature_entry(struct hlsl_ctx *ctx, struct vsir_prog
                 component_type = VKD3D_SHADER_COMPONENT_UINT;
                 break;
 
-            default:
+            case HLSL_TYPE_DOUBLE:
                 if ((string = hlsl_type_to_string(ctx, var->data_type)))
                     hlsl_error(ctx, &var->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_TYPE,
                             "Invalid data type %s for semantic variable %s.", string->buffer, var->name);
                 hlsl_release_string_buffer(ctx, string);
-                component_type = VKD3D_SHADER_COMPONENT_VOID;
                 break;
         }
 
@@ -6757,19 +6771,19 @@ static void generate_vsir_signature_entry(struct hlsl_ctx *ctx, struct vsir_prog
                 sysval = VKD3D_SHADER_SV_POSITION;
         }
 
-        mask = (1 << var->data_type->dimx) - 1;
+        mask = (1 << var->data_type->e.numeric.dimx) - 1;
 
         if (!ascii_strcasecmp(var->semantic.name, "PSIZE") && output
                 && program->shader_version.type == VKD3D_SHADER_TYPE_VERTEX)
         {
-            if (var->data_type->dimx > 1)
+            if (var->data_type->e.numeric.dimx > 1)
                 hlsl_error(ctx, &var->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_SEMANTIC,
                         "PSIZE output must have only 1 component in this shader model.");
             /* For some reason the writemask has all components set. */
             mask = VKD3DSP_WRITEMASK_ALL;
         }
         if (!ascii_strcasecmp(var->semantic.name, "FOG") && output && program->shader_version.major < 3
-                && program->shader_version.type == VKD3D_SHADER_TYPE_VERTEX && var->data_type->dimx > 1)
+                && program->shader_version.type == VKD3D_SHADER_TYPE_VERTEX && var->data_type->e.numeric.dimx > 1)
             hlsl_error(ctx, &var->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_SEMANTIC,
                     "FOG output must have only 1 component in this shader model.");
 
@@ -7058,7 +7072,7 @@ static void vsir_src_from_hlsl_node(struct vkd3d_shader_src_param *src,
         /* In SM4 constants are inlined */
         constant = hlsl_ir_constant(instr);
         vsir_src_from_hlsl_constant_value(src, ctx, &constant->value,
-                vsir_data_type_from_hlsl_instruction(ctx, instr), instr->data_type->dimx, map_writemask);
+                vsir_data_type_from_hlsl_instruction(ctx, instr), instr->data_type->e.numeric.dimx, map_writemask);
     }
     else
     {
@@ -7203,7 +7217,7 @@ static bool sm4_generate_vsir_reg_from_deref(struct hlsl_ctx *ctx, struct vsir_p
                 reg->idx[1].offset = offset / 4;
                 reg->idx_count = 2;
             }
-            *writemask = ((1u << data_type->dimx) - 1) << (offset & 3);
+            *writemask = ((1u << data_type->e.numeric.dimx) - 1) << (offset & 3);
         }
     }
     else if (var->is_input_semantic)
@@ -7224,7 +7238,7 @@ static bool sm4_generate_vsir_reg_from_deref(struct hlsl_ctx *ctx, struct vsir_p
                 reg->dimension = VSIR_DIMENSION_SCALAR;
             else
                 reg->dimension = VSIR_DIMENSION_VEC4;
-            *writemask = ((1u << data_type->dimx) - 1) << (offset % 4);
+            *writemask = ((1u << data_type->e.numeric.dimx) - 1) << (offset % 4);
         }
         else
         {
@@ -7260,7 +7274,7 @@ static bool sm4_generate_vsir_reg_from_deref(struct hlsl_ctx *ctx, struct vsir_p
                 reg->dimension = VSIR_DIMENSION_SCALAR;
             else
                 reg->dimension = VSIR_DIMENSION_VEC4;
-            *writemask = ((1u << data_type->dimx) - 1) << (offset % 4);
+            *writemask = ((1u << data_type->e.numeric.dimx) - 1) << (offset % 4);
         }
         else
         {
@@ -7487,7 +7501,7 @@ static bool sm1_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
     dst_type = instr->data_type;
 
     /* Narrowing casts were already lowered. */
-    VKD3D_ASSERT(src_type->dimx == dst_type->dimx);
+    VKD3D_ASSERT(src_type->e.numeric.dimx == dst_type->e.numeric.dimx);
 
     switch (dst_type->e.numeric.type)
     {
@@ -7513,9 +7527,6 @@ static bool sm1_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
                     hlsl_error(ctx, &instr->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_TYPE,
                             "The 'double' type is not supported for the %s profile.", ctx->profile->name);
                     break;
-
-                default:
-                    vkd3d_unreachable();
             }
             break;
 
@@ -7539,9 +7550,6 @@ static bool sm1_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
                 case HLSL_TYPE_DOUBLE:
                     hlsl_fixme(ctx, &instr->loc, "SM1 cast from double to integer.");
                     break;
-
-                default:
-                    vkd3d_unreachable();
             }
             break;
 
@@ -7566,7 +7574,6 @@ static bool sm1_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
 
         case HLSL_TYPE_BOOL:
             /* Casts to bool should have already been lowered. */
-        default:
             hlsl_fixme(ctx, &expr->node.loc, "SM1 cast from %s to %s.",
                 debug_hlsl_type(ctx, src_type), debug_hlsl_type(ctx, dst_type));
             break;
@@ -7648,7 +7655,7 @@ static bool sm1_generate_vsir_instr_expr(struct hlsl_ctx *ctx, struct vsir_progr
             break;
 
         case HLSL_OP2_DOT:
-            switch (expr->operands[0].node->data_type->dimx)
+            switch (expr->operands[0].node->data_type->e.numeric.dimx)
             {
                 case 3:
                     generate_vsir_instr_expr_single_instr_op(ctx, program, expr, VKD3DSIH_DP3, 0, 0, false);
@@ -7746,7 +7753,7 @@ static void sm1_generate_vsir_init_dst_param_from_deref(struct hlsl_ctx *ctx,
             register_index = reg.id;
         }
         else
-            writemask = (1u << deref->var->data_type->dimx) - 1;
+            writemask = (1u << deref->var->data_type->e.numeric.dimx) - 1;
 
         if (version.type == VKD3D_SHADER_TYPE_PIXEL && (!ascii_strcasecmp(semantic_name, "PSIZE")
                 || (!ascii_strcasecmp(semantic_name, "FOG") && version.major < 3)))
@@ -7804,7 +7811,7 @@ static void sm1_generate_vsir_init_src_param_from_deref(struct hlsl_ctx *ctx,
         if (sm1_register_from_semantic_name(&version, deref->var->semantic.name,
                 deref->var->semantic.index, false, &type, &register_index))
         {
-            writemask = (1 << deref->var->data_type->dimx) - 1;
+            writemask = (1 << deref->var->data_type->e.numeric.dimx) - 1;
         }
         else
         {
@@ -7942,7 +7949,7 @@ static void generate_vsir_instr_swizzle(struct hlsl_ctx *ctx,
     dst_param->write_mask = instr->reg.writemask;
 
     swizzle = hlsl_swizzle_from_writemask(val->reg.writemask);
-    swizzle = hlsl_combine_swizzles(swizzle, swizzle_instr->u.vector, instr->data_type->dimx);
+    swizzle = hlsl_combine_swizzles(swizzle, swizzle_instr->u.vector, instr->data_type->e.numeric.dimx);
     swizzle = hlsl_map_swizzle(swizzle, ins->dst[0].write_mask);
 
     src_param = &ins->src[0];
@@ -8008,7 +8015,7 @@ static void sm1_generate_vsir_instr_if(struct hlsl_ctx *ctx, struct vsir_program
         hlsl_fixme(ctx, &instr->loc, "Flatten \"if\" conditionals branches.");
         return;
     }
-    VKD3D_ASSERT(condition->data_type->dimx == 1 && condition->data_type->dimy == 1);
+    VKD3D_ASSERT(condition->data_type->e.numeric.dimx == 1 && condition->data_type->e.numeric.dimy == 1);
 
     if (!(ins = generate_vsir_add_program_instruction(ctx, program, &instr->loc, VKD3DSIH_IFC, 0, 2)))
         return;
@@ -8196,9 +8203,8 @@ D3DXPARAMETER_TYPE hlsl_sm1_base_type(const struct hlsl_type *type, bool is_comb
                 case HLSL_TYPE_INT:
                 case HLSL_TYPE_UINT:
                     return D3DXPT_INT;
-                default:
-                    vkd3d_unreachable();
             }
+            break;
 
         case HLSL_CLASS_SAMPLER:
             switch (type->sampler_dim)
@@ -8283,8 +8289,6 @@ static void write_sm1_type(struct vkd3d_bytecode_buffer *buffer,
     const struct hlsl_type *array_type = hlsl_get_multiarray_element_type(type);
     unsigned int array_size = hlsl_get_multiarray_size(type);
     struct hlsl_struct_field *field;
-    unsigned int field_count = 0;
-    size_t fields_offset = 0;
     size_t i;
 
     if (type->bytecode_offset)
@@ -8292,7 +8296,8 @@ static void write_sm1_type(struct vkd3d_bytecode_buffer *buffer,
 
     if (array_type->class == HLSL_CLASS_STRUCT)
     {
-        field_count = array_type->e.record.field_count;
+        unsigned int field_count = array_type->e.record.field_count;
+        size_t fields_offset;
 
         for (i = 0; i < field_count; ++i)
         {
@@ -8309,13 +8314,23 @@ static void write_sm1_type(struct vkd3d_bytecode_buffer *buffer,
             put_u32(buffer, field->name_bytecode_offset - ctab_start);
             put_u32(buffer, field->type->bytecode_offset - ctab_start);
         }
-    }
 
-    type->bytecode_offset = put_u32(buffer,
-            vkd3d_make_u32(hlsl_sm1_class(type), hlsl_sm1_base_type(array_type, is_combined_sampler)));
-    put_u32(buffer, vkd3d_make_u32(type->dimy, type->dimx));
-    put_u32(buffer, vkd3d_make_u32(array_size, field_count));
-    put_u32(buffer, fields_offset);
+        type->bytecode_offset = put_u32(buffer, vkd3d_make_u32(D3DXPC_STRUCT, D3DXPT_VOID));
+        put_u32(buffer, vkd3d_make_u32(1, hlsl_type_component_count(array_type)));
+        put_u32(buffer, vkd3d_make_u32(array_size, field_count));
+        put_u32(buffer, fields_offset);
+    }
+    else
+    {
+        type->bytecode_offset = put_u32(buffer,
+                vkd3d_make_u32(hlsl_sm1_class(type), hlsl_sm1_base_type(array_type, is_combined_sampler)));
+        if (hlsl_is_numeric_type(array_type))
+            put_u32(buffer, vkd3d_make_u32(array_type->e.numeric.dimy, array_type->e.numeric.dimx));
+        else
+            put_u32(buffer, vkd3d_make_u32(1, 1));
+        put_u32(buffer, vkd3d_make_u32(array_size, 0));
+        put_u32(buffer, 1);
+    }
 }
 
 static void sm1_sort_extern(struct list *sorted, struct hlsl_ir_var *to_sort)
@@ -8457,7 +8472,7 @@ static void write_sm1_uniforms(struct hlsl_ctx *ctx, struct vkd3d_bytecode_buffe
                         {
                             uint32_t u;
                             float f;
-                        } uni;
+                        } uni = {0};
 
                         switch (comp_type->e.numeric.type)
                         {
@@ -8481,9 +8496,6 @@ static void write_sm1_uniforms(struct hlsl_ctx *ctx, struct vkd3d_bytecode_buffe
                             case HLSL_TYPE_FLOAT:
                                 uni.u = var->default_values[k].number.u;
                                 break;
-
-                            default:
-                                vkd3d_unreachable();
                         }
 
                         set_u32(buffer, default_value_offset + comp_offset * sizeof(uint32_t), uni.u);
@@ -8570,7 +8582,7 @@ static void sm4_generate_vsir_instr_dcl_semantic(struct hlsl_ctx *ctx, struct vs
     {
         if (has_idx)
             idx = var->semantic.index;
-        write_mask = (1u << var->data_type->dimx) - 1;
+        write_mask = (1u << var->data_type->e.numeric.dimx) - 1;
     }
     else
     {
@@ -8706,7 +8718,7 @@ static bool sm4_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
     } one = { .f = 1.0 };
 
     /* Narrowing casts were already lowered. */
-    VKD3D_ASSERT(src_type->dimx == dst_type->dimx);
+    VKD3D_ASSERT(src_type->e.numeric.dimx == dst_type->e.numeric.dimx);
 
     switch (dst_type->e.numeric.type)
     {
@@ -8734,9 +8746,6 @@ static bool sm4_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
                 case HLSL_TYPE_DOUBLE:
                     hlsl_fixme(ctx, &expr->node.loc, "SM4 cast from double to float.");
                     return false;
-
-                default:
-                    vkd3d_unreachable();
             }
             break;
 
@@ -8760,9 +8769,6 @@ static bool sm4_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
                 case HLSL_TYPE_DOUBLE:
                     hlsl_fixme(ctx, &expr->node.loc, "SM4 cast from double to int.");
                     return false;
-
-                default:
-                    vkd3d_unreachable();
             }
             break;
 
@@ -8786,9 +8792,6 @@ static bool sm4_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
                 case HLSL_TYPE_DOUBLE:
                     hlsl_fixme(ctx, &expr->node.loc, "SM4 cast from double to uint.");
                     return false;
-
-                default:
-                    vkd3d_unreachable();
             }
             break;
 
@@ -8798,9 +8801,10 @@ static bool sm4_generate_vsir_instr_expr_cast(struct hlsl_ctx *ctx,
 
         case HLSL_TYPE_BOOL:
             /* Casts to bool should have already been lowered. */
-        default:
-            vkd3d_unreachable();
+            break;
     }
+
+    vkd3d_unreachable();
 }
 
 static void sm4_generate_vsir_expr_with_two_destinations(struct hlsl_ctx *ctx, struct vsir_program *program,
@@ -8855,7 +8859,7 @@ static void sm4_generate_vsir_rcp_using_div(struct hlsl_ctx *ctx,
     value.u[2].f = 1.0f;
     value.u[3].f = 1.0f;
     vsir_src_from_hlsl_constant_value(&ins->src[0], ctx, &value,
-            VKD3D_DATA_FLOAT, instr->data_type->dimx, dst_param->write_mask);
+            VKD3D_DATA_FLOAT, instr->data_type->e.numeric.dimx, dst_param->write_mask);
 
     vsir_src_from_hlsl_node(&ins->src[1], ctx, operand, dst_param->write_mask);
 }
@@ -9085,7 +9089,7 @@ static bool sm4_generate_vsir_instr_expr(struct hlsl_ctx *ctx,
             switch (dst_type->e.numeric.type)
             {
                 case HLSL_TYPE_FLOAT:
-                    switch (expr->operands[0].node->data_type->dimx)
+                    switch (expr->operands[0].node->data_type->e.numeric.dimx)
                     {
                         case 4:
                             generate_vsir_instr_expr_single_instr_op(ctx, program, expr, VKD3DSIH_DP4, 0, 0, false);
@@ -9380,10 +9384,10 @@ static bool sm4_generate_vsir_instr_load(struct hlsl_ctx *ctx, struct vsir_progr
 
         memset(&value, 0xff, sizeof(value));
         vsir_src_from_hlsl_constant_value(&ins->src[1], ctx, &value,
-                VKD3D_DATA_UINT, type->dimx, dst_param->write_mask);
+                VKD3D_DATA_UINT, type->e.numeric.dimx, dst_param->write_mask);
         memset(&value, 0x00, sizeof(value));
         vsir_src_from_hlsl_constant_value(&ins->src[2], ctx, &value,
-                VKD3D_DATA_UINT, type->dimx, dst_param->write_mask);
+                VKD3D_DATA_UINT, type->e.numeric.dimx, dst_param->write_mask);
     }
     else
     {
@@ -9426,7 +9430,7 @@ static bool sm4_generate_vsir_instr_resource_store(struct hlsl_ctx *ctx,
         if (!(ins = generate_vsir_add_program_instruction(ctx, program, &instr->loc, VKD3DSIH_STORE_RAW, 1, 2)))
             return false;
 
-        writemask = vkd3d_write_mask_from_component_count(value->data_type->dimx);
+        writemask = vkd3d_write_mask_from_component_count(value->data_type->e.numeric.dimx);
         if (!sm4_generate_vsir_init_dst_param_from_deref(ctx, program,
                 &ins->dst[0], &store->resource, &instr->loc, writemask))
             return false;
@@ -9458,9 +9462,9 @@ static bool sm4_generate_vsir_validate_texel_offset_aoffimmi(const struct hlsl_i
 
     if (offset->value.u[0].i < -8 || offset->value.u[0].i > 7)
         return false;
-    if (offset->node.data_type->dimx > 1 && (offset->value.u[1].i < -8 || offset->value.u[1].i > 7))
+    if (offset->node.data_type->e.numeric.dimx > 1 && (offset->value.u[1].i < -8 || offset->value.u[1].i > 7))
         return false;
-    if (offset->node.data_type->dimx > 2 && (offset->value.u[2].i < -8 || offset->value.u[2].i > 7))
+    if (offset->node.data_type->e.numeric.dimx > 2 && (offset->value.u[2].i < -8 || offset->value.u[2].i > 7))
         return false;
     return true;
 }
@@ -9477,9 +9481,9 @@ static void sm4_generate_vsir_encode_texel_offset_as_aoffimmi(
     ins->texel_offset.u = offset->value.u[0].i;
     ins->texel_offset.v = 0;
     ins->texel_offset.w = 0;
-    if (offset->node.data_type->dimx > 1)
+    if (offset->node.data_type->e.numeric.dimx > 1)
         ins->texel_offset.v = offset->value.u[1].i;
-    if (offset->node.data_type->dimx > 2)
+    if (offset->node.data_type->e.numeric.dimx > 2)
         ins->texel_offset.w = offset->value.u[2].i;
 }
 
@@ -9883,7 +9887,7 @@ static void sm4_generate_vsir_instr_if(struct hlsl_ctx *ctx, struct vsir_program
     struct hlsl_ir_node *instr = &iff->node;
     struct vkd3d_shader_instruction *ins;
 
-    VKD3D_ASSERT(iff->condition.node->data_type->dimx == 1);
+    VKD3D_ASSERT(iff->condition.node->data_type->e.numeric.dimx == 1);
 
     if (!(ins = generate_vsir_add_program_instruction(ctx, program, &instr->loc, VKD3DSIH_IF, 0, 1)))
         return;
@@ -10106,7 +10110,7 @@ static const char *string_skip_tag(const char *string)
     return string;
 }
 
-void sm4_free_extern_resources(struct extern_resource *extern_resources, unsigned int count)
+static void sm4_free_extern_resources(struct extern_resource *extern_resources, unsigned int count)
 {
     unsigned int i;
 
@@ -10117,7 +10121,7 @@ void sm4_free_extern_resources(struct extern_resource *extern_resources, unsigne
     vkd3d_free(extern_resources);
 }
 
-struct extern_resource *sm4_get_extern_resources(struct hlsl_ctx *ctx, unsigned int *count)
+static struct extern_resource *sm4_get_extern_resources(struct hlsl_ctx *ctx, unsigned int *count)
 {
     bool separate_components = ctx->profile->major_version == 5 && ctx->profile->minor_version == 0;
     struct extern_resource *extern_resources = NULL;
@@ -10280,7 +10284,8 @@ struct extern_resource *sm4_get_extern_resources(struct hlsl_ctx *ctx, unsigned
         ++*count;
     }
 
-    qsort(extern_resources, *count, sizeof(*extern_resources), sm4_compare_extern_resources);
+    if (extern_resources)
+        qsort(extern_resources, *count, sizeof(*extern_resources), sm4_compare_extern_resources);
 
     return extern_resources;
 }
@@ -10454,15 +10459,13 @@ static enum vkd3d_data_type sm4_generate_vsir_get_format_type(const struct hlsl_
 
         case HLSL_TYPE_INT:
             return VKD3D_DATA_INT;
-            break;
 
         case HLSL_TYPE_BOOL:
         case HLSL_TYPE_UINT:
             return VKD3D_DATA_UINT;
-
-        default:
-            vkd3d_unreachable();
     }
+
+    vkd3d_unreachable();
 }
 
 static void sm4_generate_vsir_add_dcl_texture(struct hlsl_ctx *ctx,
@@ -10651,6 +10654,510 @@ static void sm4_generate_vsir(struct hlsl_ctx *ctx, struct hlsl_ir_function_decl
     generate_vsir_scan_global_flags(ctx, program, func);
 }
 
+/* For some reason, for matrices, values from default value initializers end
+ * up in different components than from regular initializers. Default value
+ * initializers fill the matrix in vertical reading order
+ * (left-to-right top-to-bottom) instead of regular reading order
+ * (top-to-bottom left-to-right), so they have to be adjusted. An exception is
+ * that the order of matrix initializers for function parameters are row-major
+ * (top-to-bottom left-to-right). */
+static unsigned int get_component_index_from_default_initializer_index(struct hlsl_type *type, unsigned int index)
+{
+    unsigned int element_comp_count, element, x, y, i;
+    unsigned int base = 0;
+
+    switch (type->class)
+    {
+        case HLSL_CLASS_MATRIX:
+            x = index / type->e.numeric.dimy;
+            y = index % type->e.numeric.dimy;
+            return y * type->e.numeric.dimx + x;
+
+        case HLSL_CLASS_ARRAY:
+            element_comp_count = hlsl_type_component_count(type->e.array.type);
+            element = index / element_comp_count;
+            base = element * element_comp_count;
+            return base + get_component_index_from_default_initializer_index(type->e.array.type, index - base);
+
+        case HLSL_CLASS_STRUCT:
+            for (i = 0; i < type->e.record.field_count; ++i)
+            {
+                struct hlsl_type *field_type = type->e.record.fields[i].type;
+
+                element_comp_count = hlsl_type_component_count(field_type);
+                if (index - base < element_comp_count)
+                    return base + get_component_index_from_default_initializer_index(field_type, index - base);
+                base += element_comp_count;
+            }
+            break;
+
+        default:
+            return index;
+    }
+
+    vkd3d_unreachable();
+}
+
+static D3D_SRV_DIMENSION sm4_rdef_resource_dimension(const struct hlsl_type *type)
+{
+    switch (type->sampler_dim)
+    {
+        case HLSL_SAMPLER_DIM_1D:
+            return D3D_SRV_DIMENSION_TEXTURE1D;
+        case HLSL_SAMPLER_DIM_2D:
+            return D3D_SRV_DIMENSION_TEXTURE2D;
+        case HLSL_SAMPLER_DIM_3D:
+            return D3D_SRV_DIMENSION_TEXTURE3D;
+        case HLSL_SAMPLER_DIM_CUBE:
+            return D3D_SRV_DIMENSION_TEXTURECUBE;
+        case HLSL_SAMPLER_DIM_1DARRAY:
+            return D3D_SRV_DIMENSION_TEXTURE1DARRAY;
+        case HLSL_SAMPLER_DIM_2DARRAY:
+            return D3D_SRV_DIMENSION_TEXTURE2DARRAY;
+        case HLSL_SAMPLER_DIM_2DMS:
+            return D3D_SRV_DIMENSION_TEXTURE2DMS;
+        case HLSL_SAMPLER_DIM_2DMSARRAY:
+            return D3D_SRV_DIMENSION_TEXTURE2DMSARRAY;
+        case HLSL_SAMPLER_DIM_CUBEARRAY:
+            return D3D_SRV_DIMENSION_TEXTURECUBEARRAY;
+        case HLSL_SAMPLER_DIM_BUFFER:
+        case HLSL_SAMPLER_DIM_RAW_BUFFER:
+        case HLSL_SAMPLER_DIM_STRUCTURED_BUFFER:
+            return D3D_SRV_DIMENSION_BUFFER;
+        default:
+            break;
+    }
+
+    vkd3d_unreachable();
+}
+
+static enum D3D_RESOURCE_RETURN_TYPE sm4_data_type(const struct hlsl_type *type)
+{
+    const struct hlsl_type *format = type->e.resource.format;
+
+    switch (format->e.numeric.type)
+    {
+        case HLSL_TYPE_DOUBLE:
+            return D3D_RETURN_TYPE_DOUBLE;
+
+        case HLSL_TYPE_FLOAT:
+        case HLSL_TYPE_HALF:
+            if (format->modifiers & HLSL_MODIFIER_UNORM)
+                return D3D_RETURN_TYPE_UNORM;
+            if (format->modifiers & HLSL_MODIFIER_SNORM)
+                return D3D_RETURN_TYPE_SNORM;
+            return D3D_RETURN_TYPE_FLOAT;
+
+        case HLSL_TYPE_INT:
+            return D3D_RETURN_TYPE_SINT;
+            break;
+
+        case HLSL_TYPE_BOOL:
+        case HLSL_TYPE_UINT:
+            return D3D_RETURN_TYPE_UINT;
+    }
+
+    vkd3d_unreachable();
+}
+
+static D3D_SHADER_INPUT_TYPE sm4_resource_type(const struct hlsl_type *type)
+{
+    switch (type->class)
+    {
+        case HLSL_CLASS_SAMPLER:
+            return D3D_SIT_SAMPLER;
+        case HLSL_CLASS_TEXTURE:
+            return D3D_SIT_TEXTURE;
+        case HLSL_CLASS_UAV:
+            return D3D_SIT_UAV_RWTYPED;
+        default:
+            break;
+    }
+
+    vkd3d_unreachable();
+}
+
+static D3D_SHADER_VARIABLE_CLASS sm4_class(const struct hlsl_type *type)
+{
+    switch (type->class)
+    {
+        case HLSL_CLASS_MATRIX:
+            VKD3D_ASSERT(type->modifiers & HLSL_MODIFIERS_MAJORITY_MASK);
+            if (type->modifiers & HLSL_MODIFIER_COLUMN_MAJOR)
+                return D3D_SVC_MATRIX_COLUMNS;
+            else
+                return D3D_SVC_MATRIX_ROWS;
+        case HLSL_CLASS_SCALAR:
+            return D3D_SVC_SCALAR;
+        case HLSL_CLASS_VECTOR:
+            return D3D_SVC_VECTOR;
+
+        case HLSL_CLASS_ARRAY:
+        case HLSL_CLASS_DEPTH_STENCIL_STATE:
+        case HLSL_CLASS_DEPTH_STENCIL_VIEW:
+        case HLSL_CLASS_EFFECT_GROUP:
+        case HLSL_CLASS_ERROR:
+        case HLSL_CLASS_STRUCT:
+        case HLSL_CLASS_PASS:
+        case HLSL_CLASS_PIXEL_SHADER:
+        case HLSL_CLASS_RASTERIZER_STATE:
+        case HLSL_CLASS_RENDER_TARGET_VIEW:
+        case HLSL_CLASS_SAMPLER:
+        case HLSL_CLASS_STRING:
+        case HLSL_CLASS_TECHNIQUE:
+        case HLSL_CLASS_TEXTURE:
+        case HLSL_CLASS_UAV:
+        case HLSL_CLASS_VERTEX_SHADER:
+        case HLSL_CLASS_VOID:
+        case HLSL_CLASS_CONSTANT_BUFFER:
+        case HLSL_CLASS_COMPUTE_SHADER:
+        case HLSL_CLASS_DOMAIN_SHADER:
+        case HLSL_CLASS_HULL_SHADER:
+        case HLSL_CLASS_GEOMETRY_SHADER:
+        case HLSL_CLASS_BLEND_STATE:
+        case HLSL_CLASS_STREAM_OUTPUT:
+        case HLSL_CLASS_NULL:
+            break;
+    }
+
+    vkd3d_unreachable();
+}
+
+static D3D_SHADER_VARIABLE_TYPE sm4_base_type(const struct hlsl_type *type)
+{
+    switch (type->e.numeric.type)
+    {
+        case HLSL_TYPE_BOOL:
+            return D3D_SVT_BOOL;
+        case HLSL_TYPE_DOUBLE:
+            return D3D_SVT_DOUBLE;
+        case HLSL_TYPE_FLOAT:
+        case HLSL_TYPE_HALF:
+            return D3D_SVT_FLOAT;
+        case HLSL_TYPE_INT:
+            return D3D_SVT_INT;
+        case HLSL_TYPE_UINT:
+            return D3D_SVT_UINT;
+    }
+
+    vkd3d_unreachable();
+}
+
+static void write_sm4_type(struct hlsl_ctx *ctx, struct vkd3d_bytecode_buffer *buffer, struct hlsl_type *type)
+{
+    const struct hlsl_type *array_type = hlsl_get_multiarray_element_type(type);
+    const char *name = array_type->name ? array_type->name : "<unnamed>";
+    const struct hlsl_profile_info *profile = ctx->profile;
+    unsigned int array_size = 0;
+    size_t name_offset = 0;
+    size_t i;
+
+    if (type->bytecode_offset)
+        return;
+
+    if (profile->major_version >= 5)
+        name_offset = put_string(buffer, name);
+
+    if (type->class == HLSL_CLASS_ARRAY)
+        array_size = hlsl_get_multiarray_size(type);
+
+    if (array_type->class == HLSL_CLASS_STRUCT)
+    {
+        unsigned int field_count = 0;
+        size_t fields_offset = 0;
+
+        for (i = 0; i < array_type->e.record.field_count; ++i)
+        {
+            struct hlsl_struct_field *field = &array_type->e.record.fields[i];
+
+            if (!field->type->reg_size[HLSL_REGSET_NUMERIC])
+                continue;
+
+            field->name_bytecode_offset = put_string(buffer, field->name);
+            write_sm4_type(ctx, buffer, field->type);
+            ++field_count;
+        }
+
+        fields_offset = bytecode_align(buffer);
+
+        for (i = 0; i < array_type->e.record.field_count; ++i)
+        {
+            struct hlsl_struct_field *field = &array_type->e.record.fields[i];
+
+            if (!field->type->reg_size[HLSL_REGSET_NUMERIC])
+                continue;
+
+            put_u32(buffer, field->name_bytecode_offset);
+            put_u32(buffer, field->type->bytecode_offset);
+            put_u32(buffer, field->reg_offset[HLSL_REGSET_NUMERIC] * sizeof(float));
+        }
+        type->bytecode_offset = put_u32(buffer, vkd3d_make_u32(D3D_SVC_STRUCT, D3D_SVT_VOID));
+        put_u32(buffer, vkd3d_make_u32(1, hlsl_type_component_count(array_type)));
+        put_u32(buffer, vkd3d_make_u32(array_size, field_count));
+        put_u32(buffer, fields_offset);
+    }
+    else
+    {
+        VKD3D_ASSERT(array_type->class <= HLSL_CLASS_LAST_NUMERIC);
+        type->bytecode_offset = put_u32(buffer, vkd3d_make_u32(sm4_class(array_type), sm4_base_type(array_type)));
+        put_u32(buffer, vkd3d_make_u32(array_type->e.numeric.dimy, array_type->e.numeric.dimx));
+        put_u32(buffer, vkd3d_make_u32(array_size, 0));
+        put_u32(buffer, 1);
+    }
+
+    if (profile->major_version >= 5)
+    {
+        put_u32(buffer, 0); /* FIXME: unknown */
+        put_u32(buffer, 0); /* FIXME: unknown */
+        put_u32(buffer, 0); /* FIXME: unknown */
+        put_u32(buffer, 0); /* FIXME: unknown */
+        put_u32(buffer, name_offset);
+    }
+}
+
+static void sm4_generate_rdef(struct hlsl_ctx *ctx, struct vkd3d_shader_code *rdef)
+{
+    uint32_t binding_desc_size = (hlsl_version_ge(ctx, 5, 1) ? 10 : 8) * sizeof(uint32_t);
+    size_t cbuffers_offset, resources_offset, creator_offset, string_offset;
+    unsigned int cbuffer_count = 0, extern_resources_count, i, j;
+    size_t cbuffer_position, resource_position, creator_position;
+    const struct hlsl_profile_info *profile = ctx->profile;
+    struct vkd3d_bytecode_buffer buffer = {0};
+    struct extern_resource *extern_resources;
+    const struct hlsl_buffer *cbuffer;
+    const struct hlsl_ir_var *var;
+
+    static const uint16_t target_types[] =
+    {
+        0xffff, /* PIXEL */
+        0xfffe, /* VERTEX */
+        0x4753, /* GEOMETRY */
+        0x4853, /* HULL */
+        0x4453, /* DOMAIN */
+        0x4353, /* COMPUTE */
+    };
+
+    extern_resources = sm4_get_extern_resources(ctx, &extern_resources_count);
+
+    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
+    {
+        if (cbuffer->reg.allocated)
+            ++cbuffer_count;
+    }
+
+    put_u32(&buffer, cbuffer_count);
+    cbuffer_position = put_u32(&buffer, 0);
+    put_u32(&buffer, extern_resources_count);
+    resource_position = put_u32(&buffer, 0);
+    put_u32(&buffer, vkd3d_make_u32(vkd3d_make_u16(profile->minor_version, profile->major_version),
+            target_types[profile->type]));
+    put_u32(&buffer, 0); /* FIXME: compilation flags */
+    creator_position = put_u32(&buffer, 0);
+
+    if (profile->major_version >= 5)
+    {
+        put_u32(&buffer, hlsl_version_ge(ctx, 5, 1) ? TAG_RD11_REVERSE : TAG_RD11);
+        put_u32(&buffer, 15 * sizeof(uint32_t)); /* size of RDEF header including this header */
+        put_u32(&buffer, 6 * sizeof(uint32_t)); /* size of buffer desc */
+        put_u32(&buffer, binding_desc_size); /* size of binding desc */
+        put_u32(&buffer, 10 * sizeof(uint32_t)); /* size of variable desc */
+        put_u32(&buffer, 9 * sizeof(uint32_t)); /* size of type desc */
+        put_u32(&buffer, 3 * sizeof(uint32_t)); /* size of member desc */
+        put_u32(&buffer, 0); /* unknown; possibly a null terminator */
+    }
+
+    /* Bound resources. */
+
+    resources_offset = bytecode_align(&buffer);
+    set_u32(&buffer, resource_position, resources_offset);
+
+    for (i = 0; i < extern_resources_count; ++i)
+    {
+        const struct extern_resource *resource = &extern_resources[i];
+        uint32_t flags = 0;
+
+        if (resource->is_user_packed)
+            flags |= D3D_SIF_USERPACKED;
+
+        put_u32(&buffer, 0); /* name */
+        if (resource->buffer)
+            put_u32(&buffer, resource->buffer->type == HLSL_BUFFER_CONSTANT ? D3D_SIT_CBUFFER : D3D_SIT_TBUFFER);
+        else
+            put_u32(&buffer, sm4_resource_type(resource->component_type));
+        if (resource->regset == HLSL_REGSET_TEXTURES || resource->regset == HLSL_REGSET_UAVS)
+        {
+            unsigned int dimx = resource->component_type->e.resource.format->e.numeric.dimx;
+
+            put_u32(&buffer, sm4_data_type(resource->component_type));
+            put_u32(&buffer, sm4_rdef_resource_dimension(resource->component_type));
+            put_u32(&buffer, ~0u); /* FIXME: multisample count */
+            flags |= (dimx - 1) << VKD3D_SM4_SIF_TEXTURE_COMPONENTS_SHIFT;
+        }
+        else
+        {
+            put_u32(&buffer, 0);
+            put_u32(&buffer, 0);
+            put_u32(&buffer, 0);
+        }
+        put_u32(&buffer, resource->index);
+        put_u32(&buffer, resource->bind_count);
+        put_u32(&buffer, flags);
+
+        if (hlsl_version_ge(ctx, 5, 1))
+        {
+            put_u32(&buffer, resource->space);
+            put_u32(&buffer, resource->id);
+        }
+    }
+
+    for (i = 0; i < extern_resources_count; ++i)
+    {
+        const struct extern_resource *resource = &extern_resources[i];
+
+        string_offset = put_string(&buffer, resource->name);
+        set_u32(&buffer, resources_offset + i * binding_desc_size, string_offset);
+    }
+
+    /* Buffers. */
+
+    cbuffers_offset = bytecode_align(&buffer);
+    set_u32(&buffer, cbuffer_position, cbuffers_offset);
+    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
+    {
+        unsigned int var_count = 0;
+
+        if (!cbuffer->reg.allocated)
+            continue;
+
+        LIST_FOR_EACH_ENTRY(var, &ctx->extern_vars, struct hlsl_ir_var, extern_entry)
+        {
+            if (var->is_uniform && var->buffer == cbuffer && var->data_type->reg_size[HLSL_REGSET_NUMERIC])
+                ++var_count;
+        }
+
+        put_u32(&buffer, 0); /* name */
+        put_u32(&buffer, var_count);
+        put_u32(&buffer, 0); /* variable offset */
+        put_u32(&buffer, align(cbuffer->size, 4) * sizeof(float));
+        put_u32(&buffer, 0); /* FIXME: flags */
+        put_u32(&buffer, cbuffer->type == HLSL_BUFFER_CONSTANT ? D3D_CT_CBUFFER : D3D_CT_TBUFFER);
+    }
+
+    i = 0;
+    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
+    {
+        if (!cbuffer->reg.allocated)
+            continue;
+
+        string_offset = put_string(&buffer, cbuffer->name);
+        set_u32(&buffer, cbuffers_offset + i++ * 6 * sizeof(uint32_t), string_offset);
+    }
+
+    i = 0;
+    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
+    {
+        size_t vars_start = bytecode_align(&buffer);
+
+        if (!cbuffer->reg.allocated)
+            continue;
+
+        set_u32(&buffer, cbuffers_offset + (i++ * 6 + 2) * sizeof(uint32_t), vars_start);
+
+        LIST_FOR_EACH_ENTRY(var, &ctx->extern_vars, struct hlsl_ir_var, extern_entry)
+        {
+            uint32_t flags = 0;
+
+            if (!var->is_uniform || var->buffer != cbuffer || !var->data_type->reg_size[HLSL_REGSET_NUMERIC])
+                continue;
+
+            if (var->is_read)
+                flags |= D3D_SVF_USED;
+
+            put_u32(&buffer, 0); /* name */
+            put_u32(&buffer, var->buffer_offset * sizeof(float));
+            put_u32(&buffer, var->data_type->reg_size[HLSL_REGSET_NUMERIC] * sizeof(float));
+            put_u32(&buffer, flags);
+            put_u32(&buffer, 0); /* type */
+            put_u32(&buffer, 0); /* default value */
+
+            if (profile->major_version >= 5)
+            {
+                put_u32(&buffer, 0); /* texture start */
+                put_u32(&buffer, 0); /* texture count */
+                put_u32(&buffer, 0); /* sampler start */
+                put_u32(&buffer, 0); /* sampler count */
+            }
+        }
+
+        j = 0;
+        LIST_FOR_EACH_ENTRY(var, &ctx->extern_vars, struct hlsl_ir_var, extern_entry)
+        {
+            const unsigned int var_size = (profile->major_version >= 5 ? 10 : 6);
+            size_t var_offset = vars_start + j * var_size * sizeof(uint32_t);
+
+            if (!var->is_uniform || var->buffer != cbuffer || !var->data_type->reg_size[HLSL_REGSET_NUMERIC])
+                continue;
+
+            string_offset = put_string(&buffer, var->name);
+            set_u32(&buffer, var_offset, string_offset);
+            write_sm4_type(ctx, &buffer, var->data_type);
+            set_u32(&buffer, var_offset + 4 * sizeof(uint32_t), var->data_type->bytecode_offset);
+
+            if (var->default_values)
+            {
+                unsigned int reg_size = var->data_type->reg_size[HLSL_REGSET_NUMERIC];
+                unsigned int comp_count = hlsl_type_component_count(var->data_type);
+                unsigned int default_value_offset;
+                unsigned int k;
+
+                default_value_offset = bytecode_reserve_bytes(&buffer, reg_size * sizeof(uint32_t));
+                set_u32(&buffer, var_offset + 5 * sizeof(uint32_t), default_value_offset);
+
+                for (k = 0; k < comp_count; ++k)
+                {
+                    struct hlsl_type *comp_type = hlsl_type_get_component_type(ctx, var->data_type, k);
+                    unsigned int comp_offset, comp_index;
+                    enum hlsl_regset regset;
+
+                    if (comp_type->class == HLSL_CLASS_STRING)
+                    {
+                        hlsl_error(ctx, &var->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_TYPE,
+                                "Cannot write string default value.");
+                        continue;
+                    }
+
+                    comp_index = get_component_index_from_default_initializer_index(var->data_type, k);
+                    comp_offset = hlsl_type_get_component_offset(ctx, var->data_type, comp_index, &regset);
+                    if (regset == HLSL_REGSET_NUMERIC)
+                    {
+                        if (comp_type->e.numeric.type == HLSL_TYPE_DOUBLE)
+                            hlsl_fixme(ctx, &var->loc, "Write double default values.");
+
+                        set_u32(&buffer, default_value_offset + comp_offset * sizeof(uint32_t),
+                                var->default_values[k].number.u);
+                    }
+                }
+            }
+
+            ++j;
+        }
+    }
+
+    creator_offset = put_string(&buffer, vkd3d_shader_get_version(NULL, NULL));
+    set_u32(&buffer, creator_position, creator_offset);
+
+    sm4_free_extern_resources(extern_resources, extern_resources_count);
+
+    if (buffer.status)
+    {
+        vkd3d_free(buffer.data);
+        ctx->result = buffer.status;
+        return;
+    }
+    rdef->code = buffer.data;
+    rdef->size = buffer.size;
+}
+
 static bool loop_unrolling_generate_const_bool_store(struct hlsl_ctx *ctx, struct hlsl_ir_var *var,
         bool val, struct hlsl_block *block, struct vkd3d_shader_location *loc)
 {
diff --git a/libs/vkd3d/libs/vkd3d-shader/hlsl_constant_ops.c b/libs/vkd3d/libs/vkd3d-shader/hlsl_constant_ops.c
index cd7cd2fe6a3..e8dd4d62ae2 100644
--- a/libs/vkd3d/libs/vkd3d-shader/hlsl_constant_ops.c
+++ b/libs/vkd3d/libs/vkd3d-shader/hlsl_constant_ops.c
@@ -30,7 +30,7 @@ static bool fold_abs(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -121,7 +121,7 @@ static bool fold_bit_not(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -143,20 +143,20 @@ static bool fold_cast(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
         const struct hlsl_type *dst_type, const struct hlsl_ir_constant *src)
 {
     unsigned int k;
-    uint32_t u;
-    int32_t i;
-    double d;
-    float f;
+    uint32_t u = 0;
+    double d = 0.0;
+    float f = 0.0f;
+    int32_t i = 0;
 
-    if (dst_type->dimx != src->node.data_type->dimx
-            || dst_type->dimy != src->node.data_type->dimy)
+    if (dst_type->e.numeric.dimx != src->node.data_type->e.numeric.dimx
+            || dst_type->e.numeric.dimy != src->node.data_type->e.numeric.dimy)
     {
         FIXME("Cast from %s to %s.\n", debug_hlsl_type(ctx, src->node.data_type),
                 debug_hlsl_type(ctx, dst_type));
         return false;
     }
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (src->node.data_type->e.numeric.type)
         {
@@ -195,9 +195,6 @@ static bool fold_cast(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
                 f = !!src->value.u[k].u;
                 d = !!src->value.u[k].u;
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
 
         switch (dst_type->e.numeric.type)
@@ -222,9 +219,6 @@ static bool fold_cast(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
             case HLSL_TYPE_BOOL:
                 dst->u[k].u = u ? ~0u : 0u;
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
     }
     return true;
@@ -238,7 +232,7 @@ static bool fold_ceil(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -264,7 +258,7 @@ static bool fold_exp2(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -290,7 +284,7 @@ static bool fold_floor(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -317,7 +311,7 @@ static bool fold_fract(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -343,7 +337,7 @@ static bool fold_log2(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, con
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -388,7 +382,7 @@ static bool fold_neg(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -422,7 +416,7 @@ static bool fold_not(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -446,7 +440,7 @@ static bool fold_rcp(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -491,7 +485,7 @@ static bool fold_rsq(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -531,7 +525,7 @@ static bool fold_sat(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -557,7 +551,7 @@ static bool fold_sqrt(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, con
 
     VKD3D_ASSERT(type == src->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -603,7 +597,7 @@ static bool fold_add(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -640,7 +634,7 @@ static bool fold_and(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -667,7 +661,7 @@ static bool fold_or(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, const
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -694,7 +688,7 @@ static bool fold_bit_xor(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -719,10 +713,10 @@ static bool fold_dot(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
 
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
-    VKD3D_ASSERT(src1->node.data_type->dimx == src2->node.data_type->dimx);
+    VKD3D_ASSERT(src1->node.data_type->e.numeric.dimx == src2->node.data_type->e.numeric.dimx);
 
     dst->u[0].f = 0.0f;
-    for (k = 0; k < src1->node.data_type->dimx; ++k)
+    for (k = 0; k < src1->node.data_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -748,11 +742,11 @@ static bool fold_dp2add(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src3->node.data_type->e.numeric.type);
-    VKD3D_ASSERT(src1->node.data_type->dimx == src2->node.data_type->dimx);
-    VKD3D_ASSERT(src3->node.data_type->dimx == 1);
+    VKD3D_ASSERT(src1->node.data_type->e.numeric.dimx == src2->node.data_type->e.numeric.dimx);
+    VKD3D_ASSERT(src3->node.data_type->e.numeric.dimx == 1);
 
     dst->u[0].f = src3->value.u[0].f;
-    for (k = 0; k < src1->node.data_type->dimx; ++k)
+    for (k = 0; k < src1->node.data_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -779,7 +773,7 @@ static bool fold_div(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -846,7 +840,7 @@ static bool fold_equal(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, co
     VKD3D_ASSERT(dst_type->e.numeric.type == HLSL_TYPE_BOOL);
     VKD3D_ASSERT(src1->node.data_type->e.numeric.type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (src1->node.data_type->e.numeric.type)
         {
@@ -864,9 +858,6 @@ static bool fold_equal(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, co
             case HLSL_TYPE_BOOL:
                 dst->u[k].u = src1->value.u[k].u == src2->value.u[k].u;
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
 
         dst->u[k].u *= ~0u;
@@ -882,7 +873,7 @@ static bool fold_gequal(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
     VKD3D_ASSERT(dst_type->e.numeric.type == HLSL_TYPE_BOOL);
     VKD3D_ASSERT(src1->node.data_type->e.numeric.type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (src1->node.data_type->e.numeric.type)
         {
@@ -903,9 +894,6 @@ static bool fold_gequal(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
             case HLSL_TYPE_BOOL:
                 dst->u[k].u = src1->value.u[k].u >= src2->value.u[k].u;
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
 
         dst->u[k].u *= ~0u;
@@ -921,7 +909,7 @@ static bool fold_less(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, con
     VKD3D_ASSERT(dst_type->e.numeric.type == HLSL_TYPE_BOOL);
     VKD3D_ASSERT(src1->node.data_type->e.numeric.type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (src1->node.data_type->e.numeric.type)
         {
@@ -942,9 +930,6 @@ static bool fold_less(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, con
             case HLSL_TYPE_BOOL:
                 dst->u[k].u = src1->value.u[k].u < src2->value.u[k].u;
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
 
         dst->u[k].u *= ~0u;
@@ -960,16 +945,13 @@ static bool fold_lshift(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
     VKD3D_ASSERT(dst_type->e.numeric.type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(src2->node.data_type->e.numeric.type == HLSL_TYPE_INT);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         unsigned int shift = src2->value.u[k].u % 32;
 
         switch (src1->node.data_type->e.numeric.type)
         {
             case HLSL_TYPE_INT:
-                dst->u[k].i = src1->value.u[k].i << shift;
-                break;
-
             case HLSL_TYPE_UINT:
                 dst->u[k].u = src1->value.u[k].u << shift;
                 break;
@@ -991,7 +973,7 @@ static bool fold_max(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -1029,7 +1011,7 @@ static bool fold_min(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -1068,7 +1050,7 @@ static bool fold_mod(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -1110,7 +1092,7 @@ static bool fold_mul(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, cons
     VKD3D_ASSERT(type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (type)
         {
@@ -1144,7 +1126,7 @@ static bool fold_nequal(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
     VKD3D_ASSERT(dst_type->e.numeric.type == HLSL_TYPE_BOOL);
     VKD3D_ASSERT(src1->node.data_type->e.numeric.type == src2->node.data_type->e.numeric.type);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         switch (src1->node.data_type->e.numeric.type)
         {
@@ -1162,9 +1144,6 @@ static bool fold_nequal(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
             case HLSL_TYPE_BOOL:
                 dst->u[k].u = src1->value.u[k].u != src2->value.u[k].u;
                 break;
-
-            default:
-                vkd3d_unreachable();
         }
 
         dst->u[k].u *= ~0u;
@@ -1181,7 +1160,7 @@ static bool fold_ternary(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst,
     VKD3D_ASSERT(dst_type->e.numeric.type == src3->node.data_type->e.numeric.type);
     VKD3D_ASSERT(src1->node.data_type->e.numeric.type == HLSL_TYPE_BOOL);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
         dst->u[k] = src1->value.u[k].u ? src2->value.u[k] : src3->value.u[k];
 
     return true;
@@ -1195,7 +1174,7 @@ static bool fold_rshift(struct hlsl_ctx *ctx, struct hlsl_constant_value *dst, c
     VKD3D_ASSERT(dst_type->e.numeric.type == src1->node.data_type->e.numeric.type);
     VKD3D_ASSERT(src2->node.data_type->e.numeric.type == HLSL_TYPE_INT);
 
-    for (k = 0; k < dst_type->dimx; ++k)
+    for (k = 0; k < dst_type->e.numeric.dimx; ++k)
     {
         unsigned int shift = src2->value.u[k].u % 32;
 
@@ -1403,7 +1382,7 @@ static bool constant_is_zero(struct hlsl_ir_constant *const_arg)
     struct hlsl_type *data_type = const_arg->node.data_type;
     unsigned int k;
 
-    for (k = 0; k < data_type->dimx; ++k)
+    for (k = 0; k < data_type->e.numeric.dimx; ++k)
     {
         switch (data_type->e.numeric.type)
         {
@@ -1424,9 +1403,6 @@ static bool constant_is_zero(struct hlsl_ir_constant *const_arg)
                 if (const_arg->value.u[k].u != 0)
                     return false;
                 break;
-
-            default:
-                return false;
         }
     }
     return true;
@@ -1437,7 +1413,7 @@ static bool constant_is_one(struct hlsl_ir_constant *const_arg)
     struct hlsl_type *data_type = const_arg->node.data_type;
     unsigned int k;
 
-    for (k = 0; k < data_type->dimx; ++k)
+    for (k = 0; k < data_type->e.numeric.dimx; ++k)
     {
         switch (data_type->e.numeric.type)
         {
@@ -1462,9 +1438,6 @@ static bool constant_is_one(struct hlsl_ir_constant *const_arg)
                 if (const_arg->value.u[k].u != ~0)
                     return false;
                 break;
-
-            default:
-                return false;
         }
     }
     return true;
@@ -1589,9 +1562,71 @@ static bool is_op_commutative(enum hlsl_ir_expr_op op)
     }
 }
 
+/* Returns true iff x OPL (y OPR z) = (x OPL y) OPR (x OPL z). */
+static bool is_op_left_distributive(enum hlsl_ir_expr_op opl, enum hlsl_ir_expr_op opr, enum hlsl_base_type type)
+{
+    switch (opl)
+    {
+        case HLSL_OP2_BIT_AND:
+            return opr == HLSL_OP2_BIT_OR || opr == HLSL_OP2_BIT_XOR;
+
+        case HLSL_OP2_BIT_OR:
+            return opr == HLSL_OP2_BIT_AND;
+
+        case HLSL_OP2_DOT:
+        case HLSL_OP2_MUL:
+            return opr == HLSL_OP2_ADD && (type == HLSL_TYPE_INT || type == HLSL_TYPE_UINT);
+
+        case HLSL_OP2_MAX:
+            return opr == HLSL_OP2_MIN;
+
+        case HLSL_OP2_MIN:
+            return opr == HLSL_OP2_MAX;
+
+        default:
+            return false;
+    }
+}
+
+/* Attempt to collect together the expression (x OPL a) OPR (x OPL b) -> x OPL (a OPR b). */
+static struct hlsl_ir_node *collect_exprs(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr,
+        enum hlsl_ir_expr_op opr, struct hlsl_ir_node *node1, struct hlsl_ir_node *node2)
+{
+    enum hlsl_base_type type = instr->data_type->e.numeric.type;
+    struct hlsl_ir_node *operands[HLSL_MAX_OPERANDS] = {0};
+    struct hlsl_ir_node *ab, *res;
+    struct hlsl_ir_expr *e1, *e2;
+    enum hlsl_ir_expr_op opl;
+
+    if (!node1 || !node2 || node1->type != HLSL_IR_EXPR || node2->type != HLSL_IR_EXPR)
+        return NULL;
+    e1 = hlsl_ir_expr(node1);
+    e2 = hlsl_ir_expr(node2);
+    opl = e1->op;
+
+    if (e2->op != opl || !is_op_left_distributive(opl, opr, type))
+        return NULL;
+    if (e1->operands[0].node != e2->operands[0].node)
+        return NULL;
+    if (e1->operands[1].node->type != HLSL_IR_CONSTANT || e2->operands[1].node->type != HLSL_IR_CONSTANT)
+        return NULL;
+
+    if (!(ab = hlsl_new_binary_expr(ctx, opr, e1->operands[1].node, e2->operands[1].node)))
+        return NULL;
+    list_add_before(&instr->entry, &ab->entry);
+
+    operands[0] = e1->operands[0].node;
+    operands[1] = ab;
+
+    if (!(res = hlsl_new_expr(ctx, opl, operands, instr->data_type, &instr->loc)))
+        return NULL;
+    list_add_before(&instr->entry, &res->entry);
+    return res;
+}
+
 bool hlsl_normalize_binary_exprs(struct hlsl_ctx *ctx, struct hlsl_ir_node *instr, void *context)
 {
-    struct hlsl_ir_node *arg1 , *arg2;
+    struct hlsl_ir_node *arg1, *arg2, *tmp;
     struct hlsl_ir_expr *expr;
     enum hlsl_base_type type;
     enum hlsl_ir_expr_op op;
@@ -1612,11 +1647,17 @@ bool hlsl_normalize_binary_exprs(struct hlsl_ctx *ctx, struct hlsl_ir_node *inst
     if (!arg1 || !arg2)
         return false;
 
+    if ((tmp = collect_exprs(ctx, instr, op, arg1, arg2)))
+    {
+        /* (x OPL a) OPR (x OPL b) -> x OPL (a OPR b) */
+        hlsl_replace_node(instr, tmp);
+        return true;
+    }
+
     if (is_op_commutative(op) && arg1->type == HLSL_IR_CONSTANT && arg2->type != HLSL_IR_CONSTANT)
     {
         /* a OP x -> x OP a */
-        struct hlsl_ir_node *tmp = arg1;
-
+        tmp = arg1;
         arg1 = arg2;
         arg2 = tmp;
         progress = true;
@@ -1673,6 +1714,39 @@ bool hlsl_normalize_binary_exprs(struct hlsl_ctx *ctx, struct hlsl_ir_node *inst
             progress = true;
         }
 
+        if (!progress && e1 && (tmp = collect_exprs(ctx, instr, op, e1->operands[1].node, arg2)))
+        {
+            /* (y OPR (x OPL a)) OPR (x OPL b) -> y OPR (x OPL (a OPR b)) */
+            arg1 = e1->operands[0].node;
+            arg2 = tmp;
+            progress = true;
+        }
+
+        if (!progress && is_op_commutative(op) && e1
+                && (tmp = collect_exprs(ctx, instr, op, e1->operands[0].node, arg2)))
+        {
+            /* ((x OPL a) OPR y) OPR (x OPL b) -> (x OPL (a OPR b)) OPR y */
+            arg1 = tmp;
+            arg2 = e1->operands[1].node;
+            progress = true;
+        }
+
+        if (!progress && e2 && (tmp = collect_exprs(ctx, instr, op, arg1, e2->operands[0].node)))
+        {
+            /* (x OPL a) OPR ((x OPL b) OPR y) -> (x OPL (a OPR b)) OPR y */
+            arg1 = tmp;
+            arg2 = e2->operands[1].node;
+            progress = true;
+        }
+
+        if (!progress && is_op_commutative(op) && e2
+                && (tmp = collect_exprs(ctx, instr, op, arg1, e2->operands[1].node)))
+        {
+            /* (x OPL a) OPR (y OPR (x OPL b)) -> (x OPL (a OPR b)) OPR y */
+            arg1 = tmp;
+            arg2 = e2->operands[0].node;
+            progress = true;
+        }
     }
 
     if (progress)
@@ -1704,7 +1778,7 @@ bool hlsl_fold_constant_swizzles(struct hlsl_ctx *ctx, struct hlsl_ir_node *inst
         return false;
     src = hlsl_ir_constant(swizzle->val.node);
 
-    for (i = 0; i < swizzle->node.data_type->dimx; ++i)
+    for (i = 0; i < swizzle->node.data_type->e.numeric.dimx; ++i)
         value.u[i] = src->value.u[hlsl_swizzle_get_component(swizzle->u.vector, i)];
 
     if (!(dst = hlsl_new_constant(ctx, instr->data_type, &value, &instr->loc)))
diff --git a/libs/vkd3d/libs/vkd3d-shader/ir.c b/libs/vkd3d/libs/vkd3d-shader/ir.c
index c2e4b5a4947..3678ad0bacf 100644
--- a/libs/vkd3d/libs/vkd3d-shader/ir.c
+++ b/libs/vkd3d/libs/vkd3d-shader/ir.c
@@ -2031,7 +2031,8 @@ static bool shader_signature_merge(struct shader_signature *s, uint8_t range_map
     element_count = s->element_count;
     if (!(elements = vkd3d_malloc(element_count * sizeof(*elements))))
         return false;
-    memcpy(elements, s->elements, element_count * sizeof(*elements));
+    if (element_count)
+        memcpy(elements, s->elements, element_count * sizeof(*elements));
 
     for (i = 0; i < element_count; ++i)
         elements[i].sort_index = i;
@@ -3836,7 +3837,8 @@ static enum vkd3d_result vsir_cfg_structure_list_append_from_region(struct vsir_
             sizeof(*list->structures)))
         return VKD3D_ERROR_OUT_OF_MEMORY;
 
-    memcpy(&list->structures[list->count], begin, size * sizeof(*begin));
+    if (size)
+        memcpy(&list->structures[list->count], begin, size * sizeof(*begin));
 
     list->count += size;
 
@@ -4773,7 +4775,8 @@ static enum vkd3d_result vsir_cfg_generate_synthetic_loop_intervals(struct vsir_
         }
     }
 
-    qsort(cfg->loop_intervals, cfg->loop_interval_count, sizeof(*cfg->loop_intervals), compare_loop_intervals);
+    if (cfg->loop_intervals)
+        qsort(cfg->loop_intervals, cfg->loop_interval_count, sizeof(*cfg->loop_intervals), compare_loop_intervals);
 
     if (TRACE_ON())
         for (i = 0; i < cfg->loop_interval_count; ++i)
diff --git a/libs/vkd3d/libs/vkd3d-shader/spirv.c b/libs/vkd3d/libs/vkd3d-shader/spirv.c
index cfbadab8933..efa76983546 100644
--- a/libs/vkd3d/libs/vkd3d-shader/spirv.c
+++ b/libs/vkd3d/libs/vkd3d-shader/spirv.c
@@ -7259,12 +7259,13 @@ static void spirv_compiler_emit_shader_epilogue_invocation(struct spirv_compiler
 
 static void spirv_compiler_emit_hull_shader_main(struct spirv_compiler *compiler)
 {
+    size_t table_count = compiler->offset_info.descriptor_table_count;
     struct vkd3d_spirv_builder *builder = &compiler->spirv_builder;
     uint32_t void_id;
 
     /* If a patch constant function used descriptor indexing the offsets must be reloaded. */
-    memset(compiler->descriptor_offset_ids, 0, compiler->offset_info.descriptor_table_count
-            * sizeof(*compiler->descriptor_offset_ids));
+    if (table_count)
+        memset(compiler->descriptor_offset_ids, 0, table_count * sizeof(*compiler->descriptor_offset_ids));
     vkd3d_spirv_builder_begin_main_function(builder);
     vkd3d_spirv_build_op_label(builder, vkd3d_spirv_alloc_id(builder));
 
diff --git a/libs/vkd3d/libs/vkd3d-shader/tpf.c b/libs/vkd3d/libs/vkd3d-shader/tpf.c
index bdc1c738a32..aa666086710 100644
--- a/libs/vkd3d/libs/vkd3d-shader/tpf.c
+++ b/libs/vkd3d/libs/vkd3d-shader/tpf.c
@@ -21,9 +21,7 @@
  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
  */
 
-#include "hlsl.h"
 #include "vkd3d_shader_private.h"
-#include "d3dcommon.h"
 
 #define SM4_MAX_SRC_COUNT 6
 #define SM4_MAX_DST_COUNT 2
@@ -163,9 +161,6 @@ STATIC_ASSERT(SM4_MAX_SRC_COUNT <= SPIRV_MAX_SRC_COUNT);
 
 #define VKD3D_SM4_TYPE_COMPONENT(com, i)      (((com) >> (4 * (i))) & 0xfu)
 
-/* The shift that corresponds to the D3D_SIF_TEXTURE_COMPONENTS mask. */
-#define VKD3D_SM4_SIF_TEXTURE_COMPONENTS_SHIFT 2
-
 enum vkd3d_sm4_opcode
 {
     VKD3D_SM4_OP_ADD                              = 0x00,
@@ -3268,505 +3263,6 @@ static void tpf_write_signature(struct tpf_compiler *tpf, const struct shader_si
     vkd3d_free(sorted_elements);
 }
 
-static D3D_SHADER_VARIABLE_CLASS sm4_class(const struct hlsl_type *type)
-{
-    switch (type->class)
-    {
-        case HLSL_CLASS_MATRIX:
-            VKD3D_ASSERT(type->modifiers & HLSL_MODIFIERS_MAJORITY_MASK);
-            if (type->modifiers & HLSL_MODIFIER_COLUMN_MAJOR)
-                return D3D_SVC_MATRIX_COLUMNS;
-            else
-                return D3D_SVC_MATRIX_ROWS;
-        case HLSL_CLASS_SCALAR:
-            return D3D_SVC_SCALAR;
-        case HLSL_CLASS_VECTOR:
-            return D3D_SVC_VECTOR;
-
-        case HLSL_CLASS_ARRAY:
-        case HLSL_CLASS_DEPTH_STENCIL_STATE:
-        case HLSL_CLASS_DEPTH_STENCIL_VIEW:
-        case HLSL_CLASS_EFFECT_GROUP:
-        case HLSL_CLASS_ERROR:
-        case HLSL_CLASS_STRUCT:
-        case HLSL_CLASS_PASS:
-        case HLSL_CLASS_PIXEL_SHADER:
-        case HLSL_CLASS_RASTERIZER_STATE:
-        case HLSL_CLASS_RENDER_TARGET_VIEW:
-        case HLSL_CLASS_SAMPLER:
-        case HLSL_CLASS_STRING:
-        case HLSL_CLASS_TECHNIQUE:
-        case HLSL_CLASS_TEXTURE:
-        case HLSL_CLASS_UAV:
-        case HLSL_CLASS_VERTEX_SHADER:
-        case HLSL_CLASS_VOID:
-        case HLSL_CLASS_CONSTANT_BUFFER:
-        case HLSL_CLASS_COMPUTE_SHADER:
-        case HLSL_CLASS_DOMAIN_SHADER:
-        case HLSL_CLASS_HULL_SHADER:
-        case HLSL_CLASS_GEOMETRY_SHADER:
-        case HLSL_CLASS_BLEND_STATE:
-        case HLSL_CLASS_STREAM_OUTPUT:
-        case HLSL_CLASS_NULL:
-            break;
-    }
-    vkd3d_unreachable();
-}
-
-static D3D_SHADER_VARIABLE_TYPE sm4_base_type(const struct hlsl_type *type)
-{
-    switch (type->e.numeric.type)
-    {
-        case HLSL_TYPE_BOOL:
-            return D3D_SVT_BOOL;
-        case HLSL_TYPE_DOUBLE:
-            return D3D_SVT_DOUBLE;
-        case HLSL_TYPE_FLOAT:
-        case HLSL_TYPE_HALF:
-            return D3D_SVT_FLOAT;
-        case HLSL_TYPE_INT:
-            return D3D_SVT_INT;
-        case HLSL_TYPE_UINT:
-            return D3D_SVT_UINT;
-        default:
-            vkd3d_unreachable();
-    }
-}
-
-static void write_sm4_type(struct hlsl_ctx *ctx, struct vkd3d_bytecode_buffer *buffer, struct hlsl_type *type)
-{
-    const struct hlsl_type *array_type = hlsl_get_multiarray_element_type(type);
-    const char *name = array_type->name ? array_type->name : "<unnamed>";
-    const struct hlsl_profile_info *profile = ctx->profile;
-    unsigned int array_size = 0;
-    size_t name_offset = 0;
-    size_t i;
-
-    if (type->bytecode_offset)
-        return;
-
-    if (profile->major_version >= 5)
-        name_offset = put_string(buffer, name);
-
-    if (type->class == HLSL_CLASS_ARRAY)
-        array_size = hlsl_get_multiarray_size(type);
-
-    if (array_type->class == HLSL_CLASS_STRUCT)
-    {
-        unsigned int field_count = 0;
-        size_t fields_offset = 0;
-
-        for (i = 0; i < array_type->e.record.field_count; ++i)
-        {
-            struct hlsl_struct_field *field = &array_type->e.record.fields[i];
-
-            if (!field->type->reg_size[HLSL_REGSET_NUMERIC])
-                continue;
-
-            field->name_bytecode_offset = put_string(buffer, field->name);
-            write_sm4_type(ctx, buffer, field->type);
-            ++field_count;
-        }
-
-        fields_offset = bytecode_align(buffer);
-
-        for (i = 0; i < array_type->e.record.field_count; ++i)
-        {
-            struct hlsl_struct_field *field = &array_type->e.record.fields[i];
-
-            if (!field->type->reg_size[HLSL_REGSET_NUMERIC])
-                continue;
-
-            put_u32(buffer, field->name_bytecode_offset);
-            put_u32(buffer, field->type->bytecode_offset);
-            put_u32(buffer, field->reg_offset[HLSL_REGSET_NUMERIC] * sizeof(float));
-        }
-        type->bytecode_offset = put_u32(buffer, vkd3d_make_u32(D3D_SVC_STRUCT, D3D_SVT_VOID));
-        put_u32(buffer, vkd3d_make_u32(1, hlsl_type_component_count(array_type)));
-        put_u32(buffer, vkd3d_make_u32(array_size, field_count));
-        put_u32(buffer, fields_offset);
-    }
-    else
-    {
-        VKD3D_ASSERT(array_type->class <= HLSL_CLASS_LAST_NUMERIC);
-        type->bytecode_offset = put_u32(buffer, vkd3d_make_u32(sm4_class(array_type), sm4_base_type(array_type)));
-        put_u32(buffer, vkd3d_make_u32(array_type->dimy, array_type->dimx));
-        put_u32(buffer, vkd3d_make_u32(array_size, 0));
-        put_u32(buffer, 1);
-    }
-
-    if (profile->major_version >= 5)
-    {
-        put_u32(buffer, 0); /* FIXME: unknown */
-        put_u32(buffer, 0); /* FIXME: unknown */
-        put_u32(buffer, 0); /* FIXME: unknown */
-        put_u32(buffer, 0); /* FIXME: unknown */
-        put_u32(buffer, name_offset);
-    }
-}
-
-static D3D_SHADER_INPUT_TYPE sm4_resource_type(const struct hlsl_type *type)
-{
-    switch (type->class)
-    {
-        case HLSL_CLASS_SAMPLER:
-            return D3D_SIT_SAMPLER;
-        case HLSL_CLASS_TEXTURE:
-            return D3D_SIT_TEXTURE;
-        case HLSL_CLASS_UAV:
-            return D3D_SIT_UAV_RWTYPED;
-        default:
-            break;
-    }
-
-    vkd3d_unreachable();
-}
-
-static enum vkd3d_sm4_data_type sm4_data_type(const struct hlsl_type *type)
-{
-    const struct hlsl_type *format = type->e.resource.format;
-
-    switch (format->e.numeric.type)
-    {
-        case HLSL_TYPE_DOUBLE:
-            return VKD3D_SM4_DATA_DOUBLE;
-
-        case HLSL_TYPE_FLOAT:
-        case HLSL_TYPE_HALF:
-            if (format->modifiers & HLSL_MODIFIER_UNORM)
-                return VKD3D_SM4_DATA_UNORM;
-            if (format->modifiers & HLSL_MODIFIER_SNORM)
-                return VKD3D_SM4_DATA_SNORM;
-            return VKD3D_SM4_DATA_FLOAT;
-
-        case HLSL_TYPE_INT:
-            return VKD3D_SM4_DATA_INT;
-            break;
-
-        case HLSL_TYPE_BOOL:
-        case HLSL_TYPE_UINT:
-            return VKD3D_SM4_DATA_UINT;
-
-        default:
-            vkd3d_unreachable();
-    }
-}
-
-static D3D_SRV_DIMENSION sm4_rdef_resource_dimension(const struct hlsl_type *type)
-{
-    switch (type->sampler_dim)
-    {
-        case HLSL_SAMPLER_DIM_1D:
-            return D3D_SRV_DIMENSION_TEXTURE1D;
-        case HLSL_SAMPLER_DIM_2D:
-            return D3D_SRV_DIMENSION_TEXTURE2D;
-        case HLSL_SAMPLER_DIM_3D:
-            return D3D_SRV_DIMENSION_TEXTURE3D;
-        case HLSL_SAMPLER_DIM_CUBE:
-            return D3D_SRV_DIMENSION_TEXTURECUBE;
-        case HLSL_SAMPLER_DIM_1DARRAY:
-            return D3D_SRV_DIMENSION_TEXTURE1DARRAY;
-        case HLSL_SAMPLER_DIM_2DARRAY:
-            return D3D_SRV_DIMENSION_TEXTURE2DARRAY;
-        case HLSL_SAMPLER_DIM_2DMS:
-            return D3D_SRV_DIMENSION_TEXTURE2DMS;
-        case HLSL_SAMPLER_DIM_2DMSARRAY:
-            return D3D_SRV_DIMENSION_TEXTURE2DMSARRAY;
-        case HLSL_SAMPLER_DIM_CUBEARRAY:
-            return D3D_SRV_DIMENSION_TEXTURECUBEARRAY;
-        case HLSL_SAMPLER_DIM_BUFFER:
-        case HLSL_SAMPLER_DIM_RAW_BUFFER:
-        case HLSL_SAMPLER_DIM_STRUCTURED_BUFFER:
-            return D3D_SRV_DIMENSION_BUFFER;
-        default:
-            vkd3d_unreachable();
-    }
-}
-
-/* For some reason, for matrices, values from default value initializers end up in different
- * components than from regular initializers. Default value initializers fill the matrix in
- * vertical reading order (left-to-right top-to-bottom) instead of regular reading order
- * (top-to-bottom left-to-right), so they have to be adjusted.
- * An exception is that the order of matrix initializers for function parameters are row-major
- * (top-to-bottom left-to-right). */
-static unsigned int get_component_index_from_default_initializer_index(struct hlsl_type *type, unsigned int index)
-{
-    unsigned int element_comp_count, element, x, y, i;
-    unsigned int base = 0;
-
-    switch (type->class)
-    {
-        case HLSL_CLASS_MATRIX:
-            x = index / type->dimy;
-            y = index % type->dimy;
-            return y * type->dimx + x;
-
-        case HLSL_CLASS_ARRAY:
-            element_comp_count = hlsl_type_component_count(type->e.array.type);
-            element = index / element_comp_count;
-            base = element * element_comp_count;
-            return base + get_component_index_from_default_initializer_index(type->e.array.type, index - base);
-
-        case HLSL_CLASS_STRUCT:
-            for (i = 0; i < type->e.record.field_count; ++i)
-            {
-                struct hlsl_type *field_type = type->e.record.fields[i].type;
-
-                element_comp_count = hlsl_type_component_count(field_type);
-                if (index - base < element_comp_count)
-                    return base + get_component_index_from_default_initializer_index(field_type, index - base);
-                base += element_comp_count;
-            }
-            break;
-
-        default:
-            return index;
-    }
-    vkd3d_unreachable();
-}
-
-void sm4_generate_rdef(struct hlsl_ctx *ctx, struct vkd3d_shader_code *rdef)
-{
-    uint32_t binding_desc_size = (hlsl_version_ge(ctx, 5, 1) ? 10 : 8) * sizeof(uint32_t);
-    size_t cbuffers_offset, resources_offset, creator_offset, string_offset;
-    unsigned int cbuffer_count = 0, extern_resources_count, i, j;
-    size_t cbuffer_position, resource_position, creator_position;
-    const struct hlsl_profile_info *profile = ctx->profile;
-    struct vkd3d_bytecode_buffer buffer = {0};
-    struct extern_resource *extern_resources;
-    const struct hlsl_buffer *cbuffer;
-    const struct hlsl_ir_var *var;
-
-    static const uint16_t target_types[] =
-    {
-        0xffff, /* PIXEL */
-        0xfffe, /* VERTEX */
-        0x4753, /* GEOMETRY */
-        0x4853, /* HULL */
-        0x4453, /* DOMAIN */
-        0x4353, /* COMPUTE */
-    };
-
-    extern_resources = sm4_get_extern_resources(ctx, &extern_resources_count);
-
-    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
-    {
-        if (cbuffer->reg.allocated)
-            ++cbuffer_count;
-    }
-
-    put_u32(&buffer, cbuffer_count);
-    cbuffer_position = put_u32(&buffer, 0);
-    put_u32(&buffer, extern_resources_count);
-    resource_position = put_u32(&buffer, 0);
-    put_u32(&buffer, vkd3d_make_u32(vkd3d_make_u16(profile->minor_version, profile->major_version),
-            target_types[profile->type]));
-    put_u32(&buffer, 0); /* FIXME: compilation flags */
-    creator_position = put_u32(&buffer, 0);
-
-    if (profile->major_version >= 5)
-    {
-        put_u32(&buffer, hlsl_version_ge(ctx, 5, 1) ? TAG_RD11_REVERSE : TAG_RD11);
-        put_u32(&buffer, 15 * sizeof(uint32_t)); /* size of RDEF header including this header */
-        put_u32(&buffer, 6 * sizeof(uint32_t)); /* size of buffer desc */
-        put_u32(&buffer, binding_desc_size); /* size of binding desc */
-        put_u32(&buffer, 10 * sizeof(uint32_t)); /* size of variable desc */
-        put_u32(&buffer, 9 * sizeof(uint32_t)); /* size of type desc */
-        put_u32(&buffer, 3 * sizeof(uint32_t)); /* size of member desc */
-        put_u32(&buffer, 0); /* unknown; possibly a null terminator */
-    }
-
-    /* Bound resources. */
-
-    resources_offset = bytecode_align(&buffer);
-    set_u32(&buffer, resource_position, resources_offset);
-
-    for (i = 0; i < extern_resources_count; ++i)
-    {
-        const struct extern_resource *resource = &extern_resources[i];
-        uint32_t flags = 0;
-
-        if (resource->is_user_packed)
-            flags |= D3D_SIF_USERPACKED;
-
-        put_u32(&buffer, 0); /* name */
-        if (resource->buffer)
-            put_u32(&buffer, resource->buffer->type == HLSL_BUFFER_CONSTANT ? D3D_SIT_CBUFFER : D3D_SIT_TBUFFER);
-        else
-            put_u32(&buffer, sm4_resource_type(resource->component_type));
-        if (resource->regset == HLSL_REGSET_TEXTURES || resource->regset == HLSL_REGSET_UAVS)
-        {
-            unsigned int dimx = resource->component_type->e.resource.format->dimx;
-
-            put_u32(&buffer, sm4_data_type(resource->component_type));
-            put_u32(&buffer, sm4_rdef_resource_dimension(resource->component_type));
-            put_u32(&buffer, ~0u); /* FIXME: multisample count */
-            flags |= (dimx - 1) << VKD3D_SM4_SIF_TEXTURE_COMPONENTS_SHIFT;
-        }
-        else
-        {
-            put_u32(&buffer, 0);
-            put_u32(&buffer, 0);
-            put_u32(&buffer, 0);
-        }
-        put_u32(&buffer, resource->index);
-        put_u32(&buffer, resource->bind_count);
-        put_u32(&buffer, flags);
-
-        if (hlsl_version_ge(ctx, 5, 1))
-        {
-            put_u32(&buffer, resource->space);
-            put_u32(&buffer, resource->id);
-        }
-    }
-
-    for (i = 0; i < extern_resources_count; ++i)
-    {
-        const struct extern_resource *resource = &extern_resources[i];
-
-        string_offset = put_string(&buffer, resource->name);
-        set_u32(&buffer, resources_offset + i * binding_desc_size, string_offset);
-    }
-
-    /* Buffers. */
-
-    cbuffers_offset = bytecode_align(&buffer);
-    set_u32(&buffer, cbuffer_position, cbuffers_offset);
-    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
-    {
-        unsigned int var_count = 0;
-
-        if (!cbuffer->reg.allocated)
-            continue;
-
-        LIST_FOR_EACH_ENTRY(var, &ctx->extern_vars, struct hlsl_ir_var, extern_entry)
-        {
-            if (var->is_uniform && var->buffer == cbuffer && var->data_type->reg_size[HLSL_REGSET_NUMERIC])
-                ++var_count;
-        }
-
-        put_u32(&buffer, 0); /* name */
-        put_u32(&buffer, var_count);
-        put_u32(&buffer, 0); /* variable offset */
-        put_u32(&buffer, align(cbuffer->size, 4) * sizeof(float));
-        put_u32(&buffer, 0); /* FIXME: flags */
-        put_u32(&buffer, cbuffer->type == HLSL_BUFFER_CONSTANT ? D3D_CT_CBUFFER : D3D_CT_TBUFFER);
-    }
-
-    i = 0;
-    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
-    {
-        if (!cbuffer->reg.allocated)
-            continue;
-
-        string_offset = put_string(&buffer, cbuffer->name);
-        set_u32(&buffer, cbuffers_offset + i++ * 6 * sizeof(uint32_t), string_offset);
-    }
-
-    i = 0;
-    LIST_FOR_EACH_ENTRY(cbuffer, &ctx->buffers, struct hlsl_buffer, entry)
-    {
-        size_t vars_start = bytecode_align(&buffer);
-
-        if (!cbuffer->reg.allocated)
-            continue;
-
-        set_u32(&buffer, cbuffers_offset + (i++ * 6 + 2) * sizeof(uint32_t), vars_start);
-
-        LIST_FOR_EACH_ENTRY(var, &ctx->extern_vars, struct hlsl_ir_var, extern_entry)
-        {
-            if (var->is_uniform && var->buffer == cbuffer && var->data_type->reg_size[HLSL_REGSET_NUMERIC])
-            {
-                uint32_t flags = 0;
-
-                if (var->is_read)
-                    flags |= D3D_SVF_USED;
-
-                put_u32(&buffer, 0); /* name */
-                put_u32(&buffer, var->buffer_offset * sizeof(float));
-                put_u32(&buffer, var->data_type->reg_size[HLSL_REGSET_NUMERIC] * sizeof(float));
-                put_u32(&buffer, flags);
-                put_u32(&buffer, 0); /* type */
-                put_u32(&buffer, 0); /* default value */
-
-                if (profile->major_version >= 5)
-                {
-                    put_u32(&buffer, 0); /* texture start */
-                    put_u32(&buffer, 0); /* texture count */
-                    put_u32(&buffer, 0); /* sampler start */
-                    put_u32(&buffer, 0); /* sampler count */
-                }
-            }
-        }
-
-        j = 0;
-        LIST_FOR_EACH_ENTRY(var, &ctx->extern_vars, struct hlsl_ir_var, extern_entry)
-        {
-            if (var->is_uniform && var->buffer == cbuffer && var->data_type->reg_size[HLSL_REGSET_NUMERIC])
-            {
-                const unsigned int var_size = (profile->major_version >= 5 ? 10 : 6);
-                size_t var_offset = vars_start + j * var_size * sizeof(uint32_t);
-
-                string_offset = put_string(&buffer, var->name);
-                set_u32(&buffer, var_offset, string_offset);
-                write_sm4_type(ctx, &buffer, var->data_type);
-                set_u32(&buffer, var_offset + 4 * sizeof(uint32_t), var->data_type->bytecode_offset);
-
-                if (var->default_values)
-                {
-                    unsigned int reg_size = var->data_type->reg_size[HLSL_REGSET_NUMERIC];
-                    unsigned int comp_count = hlsl_type_component_count(var->data_type);
-                    unsigned int default_value_offset;
-                    unsigned int k;
-
-                    default_value_offset = bytecode_reserve_bytes(&buffer, reg_size * sizeof(uint32_t));
-                    set_u32(&buffer, var_offset + 5 * sizeof(uint32_t), default_value_offset);
-
-                    for (k = 0; k < comp_count; ++k)
-                    {
-                        struct hlsl_type *comp_type = hlsl_type_get_component_type(ctx, var->data_type, k);
-                        unsigned int comp_offset, comp_index;
-                        enum hlsl_regset regset;
-
-                        if (comp_type->class == HLSL_CLASS_STRING)
-                        {
-                            hlsl_error(ctx, &var->loc, VKD3D_SHADER_ERROR_HLSL_INVALID_TYPE,
-                                    "Cannot write string default value.");
-                            continue;
-                        }
-
-                        comp_index = get_component_index_from_default_initializer_index(var->data_type, k);
-                        comp_offset = hlsl_type_get_component_offset(ctx, var->data_type, comp_index, &regset);
-                        if (regset == HLSL_REGSET_NUMERIC)
-                        {
-                            if (comp_type->e.numeric.type == HLSL_TYPE_DOUBLE)
-                                hlsl_fixme(ctx, &var->loc, "Write double default values.");
-
-                            set_u32(&buffer, default_value_offset + comp_offset * sizeof(uint32_t),
-                                    var->default_values[k].number.u);
-                        }
-                    }
-                }
-                ++j;
-            }
-        }
-    }
-
-    creator_offset = put_string(&buffer, vkd3d_shader_get_version(NULL, NULL));
-    set_u32(&buffer, creator_position, creator_offset);
-
-    sm4_free_extern_resources(extern_resources, extern_resources_count);
-
-    if (buffer.status)
-    {
-        vkd3d_free(buffer.data);
-        ctx->result = buffer.status;
-        return;
-    }
-    rdef->code = buffer.data;
-    rdef->size = buffer.size;
-}
-
 static enum vkd3d_sm4_resource_type sm4_resource_dimension(enum vkd3d_shader_resource_type resource_type)
 {
     switch (resource_type)
diff --git a/libs/vkd3d/libs/vkd3d-shader/vkd3d_shader_main.c b/libs/vkd3d/libs/vkd3d-shader/vkd3d_shader_main.c
index 86ec8f15fb7..c7ad407f6fb 100644
--- a/libs/vkd3d/libs/vkd3d-shader/vkd3d_shader_main.c
+++ b/libs/vkd3d/libs/vkd3d-shader/vkd3d_shader_main.c
@@ -379,7 +379,8 @@ size_t bytecode_align(struct vkd3d_bytecode_buffer *buffer)
         return aligned_size;
     }
 
-    memset(buffer->data + buffer->size, 0xab, aligned_size - buffer->size);
+    if (aligned_size > buffer->size)
+        memset(&buffer->data[buffer->size], 0xab, aligned_size - buffer->size);
     buffer->size = aligned_size;
     return aligned_size;
 }
@@ -396,7 +397,8 @@ size_t bytecode_put_bytes_unaligned(struct vkd3d_bytecode_buffer *buffer, const
         buffer->status = VKD3D_ERROR_OUT_OF_MEMORY;
         return offset;
     }
-    memcpy(buffer->data + offset, bytes, size);
+    if (size)
+        memcpy(&buffer->data[offset], bytes, size);
     buffer->size = offset + size;
     return offset;
 }
diff --git a/libs/vkd3d/libs/vkd3d/state.c b/libs/vkd3d/libs/vkd3d/state.c
index 32f34479ea1..bd3c3758ecb 100644
--- a/libs/vkd3d/libs/vkd3d/state.c
+++ b/libs/vkd3d/libs/vkd3d/state.c
@@ -578,8 +578,9 @@ static HRESULT d3d12_root_signature_info_from_desc(struct d3d12_root_signature_i
             goto done;
     }
 
-    qsort(info->ranges, info->range_count, sizeof(*info->ranges),
-            d3d12_root_signature_info_range_compare);
+    if (info->ranges)
+        qsort(info->ranges, info->range_count, sizeof(*info->ranges),
+                d3d12_root_signature_info_range_compare);
 
     for (i = D3D12_SHADER_VISIBILITY_VERTEX; i <= D3D12_SHADER_VISIBILITY_MESH; ++i)
     {
-- 
2.45.2

